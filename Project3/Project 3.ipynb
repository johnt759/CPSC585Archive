{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dcc0463",
   "metadata": {},
   "source": [
    "# Spring 2022\n",
    "# CPSC 585 Project 3\n",
    "## Raymond Carpio\n",
    "## Yu Pan\n",
    "## Sijie Shang\n",
    "## John Tu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307d3fd",
   "metadata": {},
   "source": [
    "# 1. At the end of the last project, you applied a simple Convolutional Neural Network (CNN or “Convnet”) example to the MNIST Letters dataset. You should have found that while the EMNIST Letters are harder to learn than the MNIST digits, switching to a different network architecture led to a significant increase in model performance.\n",
    "# You may have noticed, however, that the training process was slower. This means that experiments take longer, and mistakes can be costly. You saw in Project 1 that learning curves can help to understand the training process and diagnose potential problems. Unfortunately, while the Keras fit() method does return a History object that can be used to plot a curve, it does not return until the training process is complete.\n",
    "# In order to avoid down dead-ends while adjusting and tuning your model, TensorFlow includes the TensorBoard tool and the TensorBoard notebook extension for this purpose.\n",
    "# Add the TensorBoard callback to the CNN model from the previous project, and add TensorBoard to your notebook to visualize the training process.\n",
    "## Note: if you get a 403 error when trying to use TensorBoard in Google Colab, you may need to enable third-party cookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a76cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Needed to do NumPy functions\n",
    "from matplotlib import pyplot as plt # Needed to do matplotlib operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015efe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load EMNIST dataset\n",
    "emnist_data = np.load('emnist_letters.npz')\n",
    "\n",
    "train_img = emnist_data['train_images']\n",
    "train_label = emnist_data['train_labels']\n",
    "\n",
    "test_img = emnist_data['test_images']\n",
    "test_label = emnist_data['test_labels']\n",
    "\n",
    "validate_img = emnist_data['validate_images']\n",
    "validate_label = emnist_data['validate_labels']\n",
    "\n",
    "#prepare the data\n",
    "train_img = train_img.reshape((104000, 28, 28))\n",
    "train_img = train_img.astype(\"float32\") / 255\n",
    "test_img = test_img.reshape((20800, 28, 28))\n",
    "test_img = test_img.astype(\"float32\") / 255\n",
    "validate_img = validate_img.reshape((20800, 28, 28))\n",
    "validate_img = validate_img.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a2edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad1fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "distribution_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc704dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 27\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "train_img_convnet = np.expand_dims(train_img, -1)\n",
    "test_img_convnet = np.expand_dims(test_img, -1)\n",
    "validate_img_convnet = np.expand_dims(validate_img, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c730936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                43227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,043\n",
      "Trainable params: 62,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5028a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f3e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "813/813 [==============================] - 38s 46ms/step - loss: 2.0933 - accuracy: 0.3948 - val_loss: 1.2160 - val_accuracy: 0.6442\n",
      "Epoch 2/20\n",
      "813/813 [==============================] - 42s 51ms/step - loss: 1.2003 - accuracy: 0.6385 - val_loss: 0.9313 - val_accuracy: 0.7275\n",
      "Epoch 3/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.9532 - accuracy: 0.7123 - val_loss: 0.7119 - val_accuracy: 0.7920\n",
      "Epoch 4/20\n",
      "813/813 [==============================] - 46s 56ms/step - loss: 0.7934 - accuracy: 0.7585 - val_loss: 0.5968 - val_accuracy: 0.8217\n",
      "Epoch 5/20\n",
      "813/813 [==============================] - 46s 57ms/step - loss: 0.6999 - accuracy: 0.7871 - val_loss: 0.5312 - val_accuracy: 0.8389\n",
      "Epoch 6/20\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.6469 - accuracy: 0.8019 - val_loss: 0.4946 - val_accuracy: 0.8481\n",
      "Epoch 7/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6099 - accuracy: 0.8128 - val_loss: 0.4709 - val_accuracy: 0.8576\n",
      "Epoch 8/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5843 - accuracy: 0.8204 - val_loss: 0.4483 - val_accuracy: 0.8638\n",
      "Epoch 9/20\n",
      "813/813 [==============================] - 51s 62ms/step - loss: 0.5612 - accuracy: 0.8269 - val_loss: 0.4331 - val_accuracy: 0.8669\n",
      "Epoch 10/20\n",
      "813/813 [==============================] - 50s 62ms/step - loss: 0.5438 - accuracy: 0.8332 - val_loss: 0.4192 - val_accuracy: 0.8725\n",
      "Epoch 11/20\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.5252 - accuracy: 0.8371 - val_loss: 0.4103 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "813/813 [==============================] - 51s 63ms/step - loss: 0.5132 - accuracy: 0.8423 - val_loss: 0.3976 - val_accuracy: 0.8775\n",
      "Epoch 13/20\n",
      "813/813 [==============================] - 52s 64ms/step - loss: 0.5040 - accuracy: 0.8444 - val_loss: 0.3872 - val_accuracy: 0.8822\n",
      "Epoch 14/20\n",
      "813/813 [==============================] - 49s 61ms/step - loss: 0.4922 - accuracy: 0.8477 - val_loss: 0.3779 - val_accuracy: 0.8865\n",
      "Epoch 15/20\n",
      "813/813 [==============================] - 51s 63ms/step - loss: 0.4808 - accuracy: 0.8500 - val_loss: 0.3691 - val_accuracy: 0.8881\n",
      "Epoch 16/20\n",
      "813/813 [==============================] - 53s 65ms/step - loss: 0.4750 - accuracy: 0.8524 - val_loss: 0.3687 - val_accuracy: 0.8861\n",
      "Epoch 17/20\n",
      "813/813 [==============================] - 53s 65ms/step - loss: 0.4674 - accuracy: 0.8542 - val_loss: 0.3572 - val_accuracy: 0.8917\n",
      "Epoch 18/20\n",
      "813/813 [==============================] - 54s 67ms/step - loss: 0.4605 - accuracy: 0.8561 - val_loss: 0.3539 - val_accuracy: 0.8910\n",
      "Epoch 19/20\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.4551 - accuracy: 0.8578 - val_loss: 0.3519 - val_accuracy: 0.8920\n",
      "Epoch 20/20\n",
      "813/813 [==============================] - 49s 60ms/step - loss: 0.4484 - accuracy: 0.8609 - val_loss: 0.3454 - val_accuracy: 0.8935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195113d4be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model.fit(train_img_convnet, train_label, epochs=20, batch_size=128, callbacks=[tensorboard_callback], validation_data=(validate_img_convnet, validate_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1e2def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5912), started 19 days, 0:22:35 ago. (Use '!kill 5912' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b86a1bab7a61c9a9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b86a1bab7a61c9a9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10965b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 6s 9ms/step - loss: 0.3500 - accuracy: 0.8939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3500271439552307, 0.8939422965049744]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_img_convnet, test_label, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3f5cd",
   "metadata": {},
   "source": [
    "## The performance of the default example Keras CNN on the EMNIST Letters test set is around 87-88% after 20 epochs. This will be the baseline for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f7c7e",
   "metadata": {},
   "source": [
    "# 2. Now that you have a baseline convolutional network for comparison, begin experimenting with adjusting hyperparameters and alternative architectures (e.g. adding Dense hidden layers to learn combinations of features). How much can you improve its accuracy on the validation set?\n",
    "# Use the techniques you learned in Chapters 3 and 4 of the textbook to obtain the highest accuracy you can, including:\n",
    "\n",
    "### Weight initialization\n",
    "### Choice of activation function\n",
    "### Choice of optimizer\n",
    "### Batch normalization\n",
    "### Regularization\n",
    "### Dropout\n",
    "### Early Stopping\n",
    "\n",
    "## (You will notice that some of these techniques are already in use in the Simple MNIST convnet example.)\n",
    "## You may find the slides for Chapter 3 helpful, particularly the presentation “Neural Network Training [Initialization, Preprocessing, Mini-Batching, Tuning, and Other Black Art].”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c9ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 5, 5, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 27)                43227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,299\n",
      "Trainable params: 62,171\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Try to obtain the highest accuracy possible by creating a new model with the following parameters added/changed:\n",
    "# weight initialization, activation function, optimizer, batch normalization, regularization, dropout, and early stopping\n",
    "\n",
    "def create_new_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adamax\", metrics=\"accuracy\", steps_per_execution=32)\n",
    "    return model\n",
    "\n",
    "with distribution_strategy.scope():\n",
    "  new_classifier = create_new_model()\n",
    "  new_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8696f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "813/813 [==============================] - 57s 71ms/step - loss: 1.5119 - accuracy: 0.5788 - val_loss: 1.0544 - val_accuracy: 0.7009\n",
      "Epoch 2/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.9938 - accuracy: 0.7002 - val_loss: 0.8033 - val_accuracy: 0.7596\n",
      "Epoch 3/20\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.8255 - accuracy: 0.7471 - val_loss: 0.6528 - val_accuracy: 0.8060\n",
      "Epoch 4/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.7144 - accuracy: 0.7791 - val_loss: 0.6115 - val_accuracy: 0.8159\n",
      "Epoch 5/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6400 - accuracy: 0.8026 - val_loss: 0.4986 - val_accuracy: 0.8493\n",
      "Epoch 6/20\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.5899 - accuracy: 0.8167 - val_loss: 0.4703 - val_accuracy: 0.8568\n",
      "Epoch 7/20\n",
      "813/813 [==============================] - 48s 58ms/step - loss: 0.5550 - accuracy: 0.8272 - val_loss: 0.4542 - val_accuracy: 0.8625\n",
      "Epoch 8/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5262 - accuracy: 0.8356 - val_loss: 0.4754 - val_accuracy: 0.8549\n",
      "Epoch 9/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5076 - accuracy: 0.8410 - val_loss: 0.4621 - val_accuracy: 0.8577\n",
      "Epoch 10/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4906 - accuracy: 0.8466 - val_loss: 0.3918 - val_accuracy: 0.8805\n",
      "Epoch 11/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4751 - accuracy: 0.8512 - val_loss: 0.3821 - val_accuracy: 0.8834\n",
      "Epoch 12/20\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.4638 - accuracy: 0.8553 - val_loss: 0.3830 - val_accuracy: 0.8813\n",
      "Epoch 13/20\n",
      "813/813 [==============================] - 48s 58ms/step - loss: 0.4533 - accuracy: 0.8570 - val_loss: 0.3677 - val_accuracy: 0.8847\n",
      "Epoch 14/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4445 - accuracy: 0.8597 - val_loss: 0.3806 - val_accuracy: 0.8853\n",
      "Epoch 15/20\n",
      "813/813 [==============================] - 56s 69ms/step - loss: 0.4355 - accuracy: 0.8631 - val_loss: 0.3869 - val_accuracy: 0.8829\n",
      "Epoch 16/20\n",
      "813/813 [==============================] - 51s 63ms/step - loss: 0.4273 - accuracy: 0.8660 - val_loss: 0.3871 - val_accuracy: 0.8791\n",
      "Epoch 17/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4228 - accuracy: 0.8683 - val_loss: 0.3398 - val_accuracy: 0.8953\n",
      "Epoch 18/20\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.4154 - accuracy: 0.8696 - val_loss: 0.3344 - val_accuracy: 0.8964\n",
      "Epoch 19/20\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.4087 - accuracy: 0.8709 - val_loss: 0.3362 - val_accuracy: 0.8981\n",
      "Epoch 20/20\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4035 - accuracy: 0.8731 - val_loss: 0.4210 - val_accuracy: 0.8712\n"
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "with distribution_strategy.scope():\n",
    "  new_classifier.fit(train_img_convnet, train_label, epochs=20, batch_size=128, \n",
    "                   callbacks=[tensorboard_callback], validation_data=(validate_img_convnet, validate_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac95e9a",
   "metadata": {},
   "source": [
    "## The first change made to the model was the addition of a batch normalization layer after the convolutional layers. This caused the Adam optimizer to exhibit noticeably greater variance on the validation set. Similar optimizers like RMSprop and Nadam exhibited the same behavior. The addition of a second batch normalization layer caused these optimizers to fail to converge entirely on the validation set, even as they quickly converged to nearly 100% accuracy on the training set. The batch normalization layers seem to have increased the model's overfitting behavior when used with these optimizers.\n",
    "\n",
    "## The Adagrad and Adadelta optimizers exhibted much less variance on the validation set when used with the batch normalization layers. However, they also learned much more slowly compared to the original model with the Adam optimizer. \n",
    "\n",
    "## The best performance in terms of loss and accuracy on the validation set was achieved with the Adamax optimizer. Unlike the Adam optimizer, the Adamax optimizer actually performed better on the validation set when used with a batch normalization layer, and after 20 epochs it reached 90% accuracy on both the validation and test sets, which is slightly better than the original model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36745d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 5, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                43227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,299\n",
      "Trainable params: 62,171\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 1.5184 - accuracy: 0.5732 - val_loss: 1.0362 - val_accuracy: 0.7056\n",
      "Epoch 2/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.9925 - accuracy: 0.7006 - val_loss: 0.7715 - val_accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "813/813 [==============================] - 48s 58ms/step - loss: 0.8151 - accuracy: 0.7521 - val_loss: 0.6230 - val_accuracy: 0.8140\n",
      "Epoch 4/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.7053 - accuracy: 0.7831 - val_loss: 0.5327 - val_accuracy: 0.8382\n",
      "Epoch 5/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6309 - accuracy: 0.8031 - val_loss: 0.4829 - val_accuracy: 0.8541\n",
      "Epoch 6/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5857 - accuracy: 0.8167 - val_loss: 0.4451 - val_accuracy: 0.8637\n",
      "Epoch 7/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5507 - accuracy: 0.8289 - val_loss: 0.4310 - val_accuracy: 0.8688\n",
      "Epoch 8/50\n",
      "813/813 [==============================] - 51s 63ms/step - loss: 0.5254 - accuracy: 0.8347 - val_loss: 0.4101 - val_accuracy: 0.8758\n",
      "Epoch 9/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.5036 - accuracy: 0.8425 - val_loss: 0.3912 - val_accuracy: 0.8779\n",
      "Epoch 10/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4876 - accuracy: 0.8470 - val_loss: 0.4452 - val_accuracy: 0.8623\n",
      "Epoch 11/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.4717 - accuracy: 0.8520 - val_loss: 0.4356 - val_accuracy: 0.8688\n",
      "Epoch 12/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.4615 - accuracy: 0.8554 - val_loss: 0.3602 - val_accuracy: 0.8878\n",
      "Epoch 13/50\n",
      "813/813 [==============================] - 51s 63ms/step - loss: 0.4463 - accuracy: 0.8585 - val_loss: 0.3538 - val_accuracy: 0.8919\n",
      "Epoch 14/50\n",
      "813/813 [==============================] - 50s 61ms/step - loss: 0.4367 - accuracy: 0.8625 - val_loss: 0.3702 - val_accuracy: 0.8888\n",
      "Epoch 15/50\n",
      "813/813 [==============================] - 52s 63ms/step - loss: 0.4290 - accuracy: 0.8648 - val_loss: 0.3421 - val_accuracy: 0.8933\n",
      "Epoch 16/50\n",
      "813/813 [==============================] - 49s 61ms/step - loss: 0.4187 - accuracy: 0.8675 - val_loss: 0.3323 - val_accuracy: 0.8968\n",
      "Epoch 17/50\n",
      "813/813 [==============================] - 51s 62ms/step - loss: 0.4133 - accuracy: 0.8697 - val_loss: 0.3450 - val_accuracy: 0.8917\n",
      "Epoch 18/50\n",
      "813/813 [==============================] - 51s 62ms/step - loss: 0.4061 - accuracy: 0.8714 - val_loss: 0.3277 - val_accuracy: 0.8993\n",
      "Epoch 19/50\n",
      "813/813 [==============================] - 49s 60ms/step - loss: 0.3981 - accuracy: 0.8741 - val_loss: 0.4559 - val_accuracy: 0.8587\n",
      "Epoch 20/50\n",
      "813/813 [==============================] - 51s 62ms/step - loss: 0.3917 - accuracy: 0.8753 - val_loss: 0.3384 - val_accuracy: 0.8947\n",
      "Epoch 21/50\n",
      "813/813 [==============================] - 55s 68ms/step - loss: 0.3859 - accuracy: 0.8782 - val_loss: 0.3846 - val_accuracy: 0.8768\n",
      "Epoch 22/50\n",
      "813/813 [==============================] - 52s 64ms/step - loss: 0.3824 - accuracy: 0.8792 - val_loss: 0.3047 - val_accuracy: 0.9037\n",
      "Epoch 23/50\n",
      "813/813 [==============================] - 53s 65ms/step - loss: 0.3770 - accuracy: 0.8801 - val_loss: 0.3107 - val_accuracy: 0.9028\n",
      "Epoch 24/50\n",
      "813/813 [==============================] - 52s 64ms/step - loss: 0.3710 - accuracy: 0.8822 - val_loss: 0.2973 - val_accuracy: 0.9068\n",
      "Epoch 25/50\n",
      "813/813 [==============================] - 53s 65ms/step - loss: 0.3657 - accuracy: 0.8830 - val_loss: 0.2927 - val_accuracy: 0.9084\n",
      "Epoch 26/50\n",
      "813/813 [==============================] - 52s 64ms/step - loss: 0.3642 - accuracy: 0.8850 - val_loss: 0.3034 - val_accuracy: 0.9047\n",
      "Epoch 27/50\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.3566 - accuracy: 0.8865 - val_loss: 0.3052 - val_accuracy: 0.9042\n",
      "Epoch 28/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3546 - accuracy: 0.8862 - val_loss: 0.3016 - val_accuracy: 0.9052\n",
      "Epoch 29/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3544 - accuracy: 0.8871 - val_loss: 0.2885 - val_accuracy: 0.9091\n",
      "Epoch 30/50\n",
      "813/813 [==============================] - 53s 65ms/step - loss: 0.3471 - accuracy: 0.8895 - val_loss: 0.2951 - val_accuracy: 0.9083\n",
      "Epoch 31/50\n",
      "813/813 [==============================] - 50s 61ms/step - loss: 0.3467 - accuracy: 0.8899 - val_loss: 0.2850 - val_accuracy: 0.9099\n",
      "Epoch 32/50\n",
      "813/813 [==============================] - 49s 60ms/step - loss: 0.3419 - accuracy: 0.8909 - val_loss: 0.2873 - val_accuracy: 0.9103\n",
      "Epoch 33/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3419 - accuracy: 0.8906 - val_loss: 0.3000 - val_accuracy: 0.9049\n",
      "Epoch 34/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3376 - accuracy: 0.8921 - val_loss: 0.3046 - val_accuracy: 0.9033\n",
      "Epoch 35/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3356 - accuracy: 0.8924 - val_loss: 0.2741 - val_accuracy: 0.9137\n",
      "Epoch 36/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3312 - accuracy: 0.8935 - val_loss: 0.2696 - val_accuracy: 0.9160\n",
      "Epoch 37/50\n",
      "813/813 [==============================] - 48s 58ms/step - loss: 0.3309 - accuracy: 0.8947 - val_loss: 0.2794 - val_accuracy: 0.9125\n",
      "Epoch 38/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3305 - accuracy: 0.8937 - val_loss: 0.2893 - val_accuracy: 0.9090\n",
      "Epoch 39/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3264 - accuracy: 0.8945 - val_loss: 0.2723 - val_accuracy: 0.9140\n",
      "Epoch 40/50\n",
      "813/813 [==============================] - 46s 57ms/step - loss: 0.3255 - accuracy: 0.8939 - val_loss: 0.2709 - val_accuracy: 0.9156\n",
      "Epoch 41/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3248 - accuracy: 0.8961 - val_loss: 0.2727 - val_accuracy: 0.9138\n",
      "Epoch 42/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3226 - accuracy: 0.8969 - val_loss: 0.2615 - val_accuracy: 0.9192\n",
      "Epoch 43/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3204 - accuracy: 0.8965 - val_loss: 0.2654 - val_accuracy: 0.9176\n",
      "Epoch 44/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3185 - accuracy: 0.8980 - val_loss: 0.2867 - val_accuracy: 0.9100\n",
      "Epoch 45/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3171 - accuracy: 0.8983 - val_loss: 0.2668 - val_accuracy: 0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "813/813 [==============================] - 46s 57ms/step - loss: 0.3163 - accuracy: 0.8981 - val_loss: 0.2754 - val_accuracy: 0.9144\n",
      "Epoch 47/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3122 - accuracy: 0.8994 - val_loss: 0.2798 - val_accuracy: 0.9127\n",
      "Epoch 48/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3102 - accuracy: 0.9003 - val_loss: 0.2658 - val_accuracy: 0.9160\n",
      "Epoch 49/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.3119 - accuracy: 0.8990 - val_loss: 0.2609 - val_accuracy: 0.9180\n",
      "Epoch 50/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.3096 - accuracy: 0.8996 - val_loss: 0.2750 - val_accuracy: 0.9143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19512a3adf0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Early stopping\n",
    "new_classifier_ES = create_new_model()\n",
    "new_classifier_ES.summary()\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbackES = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbackTB = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "new_classifier_ES.fit(x=train_img_convnet, y=train_label, epochs=50, batch_size=128, callbacks=[callbackES, callbackTB], validation_data=(validate_img_convnet, validate_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f86ad",
   "metadata": {},
   "source": [
    "## Early stopping with restore best weights set to True was added to the previous model to address the variance in validation set loss and accuracy. This ensured that the final model used on the test set would have the weights that resulted in the best performance on the validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430dd6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 5, 5, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 27)                43227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,299\n",
      "Trainable params: 62,171\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#change weight initializers\n",
    "def new_model_l2_weight():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=initializers.HeUniform(),\n",
    "                                     kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=initializers.HeUniform(),\n",
    "                                     kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\",\n",
    "                                    kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adamax\", metrics=\"accuracy\", steps_per_execution=32)\n",
    "    return model\n",
    "\n",
    "model_IW = new_model_l2_weight()\n",
    "model_IW.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a4a1334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 1.4412 - accuracy: 0.6363 - val_loss: 1.0330 - val_accuracy: 0.7621\n",
      "Epoch 2/50\n",
      "813/813 [==============================] - 47s 57ms/step - loss: 0.9342 - accuracy: 0.7721 - val_loss: 0.8753 - val_accuracy: 0.7951\n",
      "Epoch 3/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.7889 - accuracy: 0.8143 - val_loss: 0.6784 - val_accuracy: 0.8542\n",
      "Epoch 4/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.7183 - accuracy: 0.8360 - val_loss: 0.6758 - val_accuracy: 0.8525\n",
      "Epoch 5/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.6771 - accuracy: 0.8475 - val_loss: 0.6033 - val_accuracy: 0.8747\n",
      "Epoch 6/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6509 - accuracy: 0.8548 - val_loss: 0.5939 - val_accuracy: 0.8718\n",
      "Epoch 7/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6322 - accuracy: 0.8575 - val_loss: 0.5611 - val_accuracy: 0.8829\n",
      "Epoch 8/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.6159 - accuracy: 0.8626 - val_loss: 0.5605 - val_accuracy: 0.8816\n",
      "Epoch 9/50\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.6034 - accuracy: 0.8647 - val_loss: 0.5516 - val_accuracy: 0.8832\n",
      "Epoch 10/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5919 - accuracy: 0.8680 - val_loss: 0.5782 - val_accuracy: 0.8735\n",
      "Epoch 11/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5841 - accuracy: 0.8688 - val_loss: 0.5550 - val_accuracy: 0.8808\n",
      "Epoch 12/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5749 - accuracy: 0.8721 - val_loss: 0.5227 - val_accuracy: 0.8891\n",
      "Epoch 13/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5688 - accuracy: 0.8728 - val_loss: 0.5395 - val_accuracy: 0.8817\n",
      "Epoch 14/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.5642 - accuracy: 0.8731 - val_loss: 0.5166 - val_accuracy: 0.8904\n",
      "Epoch 15/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5574 - accuracy: 0.8743 - val_loss: 0.5493 - val_accuracy: 0.8773\n",
      "Epoch 16/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5523 - accuracy: 0.8753 - val_loss: 0.4942 - val_accuracy: 0.8946\n",
      "Epoch 17/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5493 - accuracy: 0.8755 - val_loss: 0.5093 - val_accuracy: 0.8885\n",
      "Epoch 18/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5437 - accuracy: 0.8774 - val_loss: 0.5910 - val_accuracy: 0.8637\n",
      "Epoch 19/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5395 - accuracy: 0.8783 - val_loss: 0.5708 - val_accuracy: 0.8744\n",
      "Epoch 20/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5348 - accuracy: 0.8787 - val_loss: 0.4813 - val_accuracy: 0.8973\n",
      "Epoch 21/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5308 - accuracy: 0.8804 - val_loss: 0.4779 - val_accuracy: 0.8992\n",
      "Epoch 22/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5274 - accuracy: 0.8801 - val_loss: 0.4784 - val_accuracy: 0.8967\n",
      "Epoch 23/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5268 - accuracy: 0.8803 - val_loss: 0.5122 - val_accuracy: 0.8859\n",
      "Epoch 24/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5223 - accuracy: 0.8818 - val_loss: 0.4768 - val_accuracy: 0.8962\n",
      "Epoch 25/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.5194 - accuracy: 0.8820 - val_loss: 0.4786 - val_accuracy: 0.8954\n",
      "Epoch 26/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5169 - accuracy: 0.8819 - val_loss: 0.5038 - val_accuracy: 0.8870\n",
      "Epoch 27/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5167 - accuracy: 0.8822 - val_loss: 0.6388 - val_accuracy: 0.8446\n",
      "Epoch 28/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.5116 - accuracy: 0.8832 - val_loss: 0.5307 - val_accuracy: 0.8802\n",
      "Epoch 29/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5106 - accuracy: 0.8832 - val_loss: 0.4573 - val_accuracy: 0.9029\n",
      "Epoch 30/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5081 - accuracy: 0.8841 - val_loss: 0.4624 - val_accuracy: 0.8992\n",
      "Epoch 31/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5048 - accuracy: 0.8849 - val_loss: 0.4849 - val_accuracy: 0.8925\n",
      "Epoch 32/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5056 - accuracy: 0.8846 - val_loss: 0.4560 - val_accuracy: 0.9012\n",
      "Epoch 33/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5004 - accuracy: 0.8855 - val_loss: 0.4697 - val_accuracy: 0.8960\n",
      "Epoch 34/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.5016 - accuracy: 0.8849 - val_loss: 0.4725 - val_accuracy: 0.8942\n",
      "Epoch 35/50\n",
      "813/813 [==============================] - 50s 62ms/step - loss: 0.4978 - accuracy: 0.8864 - val_loss: 0.4579 - val_accuracy: 0.9014\n",
      "Epoch 36/50\n",
      "813/813 [==============================] - 48s 60ms/step - loss: 0.4957 - accuracy: 0.8869 - val_loss: 0.5742 - val_accuracy: 0.8650\n",
      "Epoch 37/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4954 - accuracy: 0.8855 - val_loss: 0.4410 - val_accuracy: 0.9029\n",
      "Epoch 38/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4933 - accuracy: 0.8865 - val_loss: 0.4690 - val_accuracy: 0.8971\n",
      "Epoch 39/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4915 - accuracy: 0.8865 - val_loss: 0.4685 - val_accuracy: 0.8976\n",
      "Epoch 40/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4901 - accuracy: 0.8876 - val_loss: 0.4451 - val_accuracy: 0.9029\n",
      "Epoch 41/50\n",
      "813/813 [==============================] - 48s 59ms/step - loss: 0.4888 - accuracy: 0.8868 - val_loss: 0.4567 - val_accuracy: 0.9000\n",
      "Epoch 42/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4859 - accuracy: 0.8881 - val_loss: 0.5175 - val_accuracy: 0.8825\n",
      "Epoch 43/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4851 - accuracy: 0.8886 - val_loss: 0.4404 - val_accuracy: 0.9049\n",
      "Epoch 44/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4853 - accuracy: 0.8879 - val_loss: 0.4684 - val_accuracy: 0.8914\n",
      "Epoch 45/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4835 - accuracy: 0.8885 - val_loss: 0.5553 - val_accuracy: 0.8633\n",
      "Epoch 46/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4844 - accuracy: 0.8874 - val_loss: 0.4972 - val_accuracy: 0.8837\n",
      "Epoch 47/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4834 - accuracy: 0.8865 - val_loss: 0.5531 - val_accuracy: 0.8672\n",
      "Epoch 48/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4790 - accuracy: 0.8883 - val_loss: 0.5373 - val_accuracy: 0.8727\n",
      "Epoch 49/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4803 - accuracy: 0.8881 - val_loss: 0.5203 - val_accuracy: 0.8754\n",
      "Epoch 50/50\n",
      "813/813 [==============================] - 47s 58ms/step - loss: 0.4778 - accuracy: 0.8894 - val_loss: 0.4732 - val_accuracy: 0.8920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19512f97fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbackES = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbackTB = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "model_IW.fit(x=train_img_convnet, y=train_label, epochs=50, batch_size=128, callbacks=[callbackES, callbackTB], validation_data=(validate_img_convnet, validate_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f129a183",
   "metadata": {},
   "source": [
    "## Further adjustments were made to the model by changing some layer initializations and adding L2 regularization. The convolutional layers' initialization was changed to He (Kaiming) Initialization, which is recommended for ReLU activation (uniform is also said to be slightly preferable to normal). The default Glorot (Xavier) Initialization for the Dense layer is already the recommended for softmax activation, so that was not changed. L2 regularization was added to all layers in an attempt to decrease the remaining variance seen in the validation set results. \n",
    "\n",
    "## Neither of these adjustments appears to have improved the model's learning and prediction behavior. This is most likely due to the fact that the batch normalization and dropout layers have already corrected for overfitting to a point where other techniques that correct for overfitting will not have any additional benefits. Both this model and the previous model perform almost identically on the validation set, and any slight performance differences tended to favor the earlier model without the additional regularization techniques applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03129405",
   "metadata": {},
   "source": [
    "# 3. When finished tuning, save your model and evaluate the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c05831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: new_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5912), started 19 days, 1:58:47 ago. (Use '!kill 5912' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9afa9d16d53e1cab\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9afa9d16d53e1cab\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_classifier_ES.save(\"new_model\")\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc8875",
   "metadata": {},
   "source": [
    "## Since both Adamax models perform almost identically on the validation set, and slight performance differences tended to favor the earlier model without the additional regularization techniques applied, the model without the additional regularization was chosen to be the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb067591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 4s 6ms/step - loss: 0.2809 - accuracy: 0.9137\n",
      "650/650 [==============================] - 4s 6ms/step - loss: 0.4779 - accuracy: 0.8909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4778617024421692, 0.8909134864807129]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classifier_ES.evaluate(test_img_convnet, test_label, verbose=1)\n",
    "model_IW.evaluate(test_img_convnet, test_label, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c9709",
   "metadata": {},
   "source": [
    "# 4. Now build and train a new model for the Binary Alphadigits dataset. What is the best validation accuracy that you can achieve?\n",
    "## Note: this dataset does not include separate validation and test sets, so you will need to use another method such as the using the validation_split parameter rather than validation_data. While it is possible to improve performance using cross-validation, as described in Chapter 4 it is generally regarded as too expensive to train, especially when (as we will soon see), there are other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff91730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1014, 320)\n",
      "(1014, 27)\n"
     ]
    }
   ],
   "source": [
    "binary_alphadigits=np.load('binaryalphadigs.npz') # Load the dataset with NumPy.\n",
    "\n",
    "binary_images = binary_alphadigits['images']\n",
    "binary_labels = binary_alphadigits['labels']\n",
    "\n",
    "# Inspect the contents of Binary Alphadigits dataset.\n",
    "print(binary_images.shape)\n",
    "print(binary_labels.shape)\n",
    "\n",
    "# Reshape the size for binary_images.\n",
    "binary_images = binary_images.reshape(1014, 20, 16)\n",
    "binary_images2 = np.expand_dims(binary_images, -1)\n",
    "input_shape2 = (20, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec840503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 18, 14, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 9, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 5, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 3, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 3, 2, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 27)                10395     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,467\n",
      "Trainable params: 29,339\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a similar model from problem 2, except try to add different hyperparameters to improve accuracy.\n",
    "def create_new_model_3():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=input_shape2))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", \n",
    "                                     kernel_initializer=initializers.HeUniform(), \n",
    "                                     kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",\n",
    "                                     kernel_initializer=initializers.HeUniform(), \n",
    "                                     kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation=\"softmax\",\n",
    "                                    kernel_regularizer=regularizers.l2(0.001), bias_regularizer=regularizers.l2(0.001)))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "    return model\n",
    "\n",
    "new_classifier_2 = create_new_model_3()\n",
    "new_classifier_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa9c1a",
   "metadata": {},
   "source": [
    "## Although the model that performed best on the EMNIST Letters dataset was a model with an Adamax optimizer, no L1 or L2 regularization, and no change to the default Keras initializations for each layer, the Adamax optimizer learned too slowly for the Binary Alphadigits dataset compared to the Adam optimizer, so the optimizer for the Binary Alphadigits model was changed back to Adam, and the initialization changes and L2 regularization were reintroduced to regularize the variance in the Adam optimizer's predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b80a7ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 4.5513 - accuracy: 0.0691 - val_loss: 4.5245 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 3.3995 - accuracy: 0.1800 - val_loss: 4.7672 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 2.7461 - accuracy: 0.2972 - val_loss: 4.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 2.4025 - accuracy: 0.3613 - val_loss: 5.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 2.1421 - accuracy: 0.4118 - val_loss: 5.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 1.9209 - accuracy: 0.4883 - val_loss: 5.1259 - val_accuracy: 0.0049\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 1.7923 - accuracy: 0.5080 - val_loss: 5.0865 - val_accuracy: 0.0049\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 1.6304 - accuracy: 0.5672 - val_loss: 5.0925 - val_accuracy: 0.0049\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 1.5704 - accuracy: 0.5771 - val_loss: 5.0894 - val_accuracy: 0.0049\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 1.4811 - accuracy: 0.6054 - val_loss: 5.0334 - val_accuracy: 0.0049\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 1.3726 - accuracy: 0.6227 - val_loss: 4.9272 - val_accuracy: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195135cbeb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbackES = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "callbackTB = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "new_classifier_2.fit(binary_images2, binary_labels, epochs=50, batch_size=128, callbacks=[callbackES, callbackTB], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f18efb",
   "metadata": {},
   "source": [
    "## Some runs produced validation accuracy over 2%, but this was rare, so the 1.5% accuracy is more representative of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f778c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 5912), started 19 days, 1:59:00 ago. (Use '!kill 5912' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-20a76bee29a51bc6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-20a76bee29a51bc6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e056e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 3.6749 - accuracy: 0.0937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.6749494075775146, 0.09368836134672165]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classifier_2.evaluate(binary_images2, binary_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154219c3",
   "metadata": {},
   "source": [
    "## Interesting to note that the prediction accuracy on the test set is higher than on the validation set. This is most likely due to the fact that the validation set, instead of being an entirely separate set of data as in the case of the EMNIST Letters, was simply a very small random portion of the training set, and therefore likely to contain samples in the set that were not learned well during training since training accuracy was only about 60%. Meanwhile the test set is a completely separate set of data, which may contain slighty more samples that were learned well during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb0fcce",
   "metadata": {},
   "source": [
    "# 5. From your experience in experiment (4), what can you conclude about the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e175d",
   "metadata": {},
   "source": [
    "## A: From what I learned so far in experiment 4, the dataset is smaller in size than the EMNIST letters dataset, which explains that it takes less time to fit the model and evaluate.  Based on the training accuracy obtained for Binary Alphadigits, I can also conclude that underfitting occurred due to the small number of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59485600",
   "metadata": {},
   "source": [
    "# 6. The process of transfer learning can be used to apply an existing model to a new dataset. Use the Keras Developer Guide Transfer learning & fine-tuning to apply the model you saved in step (3) to the Binary Alphadigits dataset.\n",
    "# Note that since the images are different sizes in the two datasets, you will need to use tf.image.resize_with_pad() to get them into the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a559c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.image import ResizeMethod\n",
    "\n",
    "resized_image = tf.image.resize_with_pad(\n",
    "    binary_images2,\n",
    "    target_height = 28,\n",
    "    target_width = 28,\n",
    "    method=ResizeMethod.BILINEAR,\n",
    "    antialias=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7908f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 5, 5, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 27)                43227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,299\n",
      "Trainable params: 62,171\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "reconstructed_model = keras.models.load_model(\"new_model\")\n",
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56198409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 2722.5149 - accuracy: 0.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2722.514892578125, 0.18047337234020233]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the unmodified saved model on the Binary Alphadigits dataset without affecting base for new model\n",
    "reconstructed_model1 = reconstructed_model\n",
    "reconstructed_model1.evaluate(resized_image, binary_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8a62f",
   "metadata": {},
   "source": [
    "# Is the model you trained on EMNIST Letters about to recognize letters from this new dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94689f5e",
   "metadata": {},
   "source": [
    "## A: Based on the accuracy obtained for this problem, the model trained on EMNIST letters is able to recognize the letter from the new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a9d222",
   "metadata": {},
   "source": [
    "# 7. Can you improve the performance by adding additional trainable layers and fine-tuning the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "936ec488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the model and manually remove the non-convolutional layers\n",
    "inner_model = tf.keras.Sequential()\n",
    "for layer in reconstructed_model.layers[0:4]:\n",
    "  inner_model.add(layer)\n",
    "\n",
    "#freeze the layers\n",
    "for layer in inner_model.layers:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8585cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 5, 5, 64)          18816     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 435,611\n",
      "Trainable params: 416,795\n",
      "Non-trainable params: 18,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct a model on top of base\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = inner_model(inputs, training=False)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "#base + newly constructed layers\n",
    "transfer_model = keras.Model(inputs, outputs)\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "422cfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62cc4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 51ms/step - loss: 13.1849 - categorical_accuracy: 0.0932 - val_loss: 13.8195 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 6.3033 - categorical_accuracy: 0.2829 - val_loss: 11.5034 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 3.4594 - categorical_accuracy: 0.3969 - val_loss: 8.0670 - val_categorical_accuracy: 0.0392\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 2.2807 - categorical_accuracy: 0.4693 - val_loss: 7.9296 - val_categorical_accuracy: 0.0098\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.9154 - categorical_accuracy: 0.4901 - val_loss: 6.4532 - val_categorical_accuracy: 0.0098\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5504 - categorical_accuracy: 0.5471 - val_loss: 6.5607 - val_categorical_accuracy: 0.0784\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 1.3985 - categorical_accuracy: 0.5921 - val_loss: 7.5259 - val_categorical_accuracy: 0.0980\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1.2828 - categorical_accuracy: 0.6250 - val_loss: 7.9352 - val_categorical_accuracy: 0.1078\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 1.1643 - categorical_accuracy: 0.6678 - val_loss: 8.8582 - val_categorical_accuracy: 0.1373\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0408 - categorical_accuracy: 0.7039 - val_loss: 10.1727 - val_categorical_accuracy: 0.1569\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.9271 - categorical_accuracy: 0.7336 - val_loss: 10.3355 - val_categorical_accuracy: 0.1373\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.8710 - categorical_accuracy: 0.7401 - val_loss: 10.6626 - val_categorical_accuracy: 0.1373\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 0.7904 - categorical_accuracy: 0.7664 - val_loss: 11.5846 - val_categorical_accuracy: 0.1667\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.8081 - categorical_accuracy: 0.7555 - val_loss: 12.8480 - val_categorical_accuracy: 0.1373\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.8430 - categorical_accuracy: 0.7643 - val_loss: 12.2200 - val_categorical_accuracy: 0.1765\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.6775 - categorical_accuracy: 0.7862 - val_loss: 12.1649 - val_categorical_accuracy: 0.1667\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.6345 - categorical_accuracy: 0.8103 - val_loss: 13.2316 - val_categorical_accuracy: 0.1863\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.5556 - categorical_accuracy: 0.8322 - val_loss: 14.0253 - val_categorical_accuracy: 0.1471\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.5840 - categorical_accuracy: 0.8355 - val_loss: 14.8116 - val_categorical_accuracy: 0.1863\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.5775 - categorical_accuracy: 0.8289 - val_loss: 14.2335 - val_categorical_accuracy: 0.1667\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.4719 - categorical_accuracy: 0.8596 - val_loss: 14.2605 - val_categorical_accuracy: 0.1569\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.4498 - categorical_accuracy: 0.8564 - val_loss: 14.7731 - val_categorical_accuracy: 0.1765\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.4201 - categorical_accuracy: 0.8651 - val_loss: 15.1413 - val_categorical_accuracy: 0.1765\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.4411 - categorical_accuracy: 0.8629 - val_loss: 15.4988 - val_categorical_accuracy: 0.1569\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.4299 - categorical_accuracy: 0.8607 - val_loss: 15.8788 - val_categorical_accuracy: 0.1667\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.4182 - categorical_accuracy: 0.8607 - val_loss: 16.0796 - val_categorical_accuracy: 0.1863\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.3837 - categorical_accuracy: 0.8849 - val_loss: 15.6112 - val_categorical_accuracy: 0.1765\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.3757 - categorical_accuracy: 0.8750 - val_loss: 15.6183 - val_categorical_accuracy: 0.1667\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3276 - categorical_accuracy: 0.8969 - val_loss: 16.9187 - val_categorical_accuracy: 0.1667\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3781 - categorical_accuracy: 0.8816 - val_loss: 16.5366 - val_categorical_accuracy: 0.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x195134c7f10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='categorical_accuracy', patience=10, restore_best_weights=True)\n",
    "transfer_model.fit(resized_image, binary_labels, epochs=30, batch_size=128, callbacks=[callback], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbb398",
   "metadata": {},
   "source": [
    "## To our saved model from Part 2, we added a single Dense layer before the output layer. This did not seem to improve model performance on the Binary Alphadigits dataset, as the baseline from the unchanged Part 2 model was 22% accuracy. It is unclear to us why loss begins to consistently increase (as opposed to merely fluctuate) on the validation set even as accuracy also continues to increase. Some sources say this may be due to the model beginning to overfit while continuing to learn at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44328a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 5, 5, 64)          18816     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 435,611\n",
      "Trainable params: 435,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fine tune by unfreezing the base_model and re-compiling\n",
    "inner_model.trainable = True\n",
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0443c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e775e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3129 - categorical_accuracy: 0.9013 - val_loss: 16.4776 - val_categorical_accuracy: 0.1765\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2657 - categorical_accuracy: 0.9024 - val_loss: 16.4564 - val_categorical_accuracy: 0.1765\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3128 - categorical_accuracy: 0.8991 - val_loss: 16.4458 - val_categorical_accuracy: 0.1765\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.3304 - categorical_accuracy: 0.8958 - val_loss: 16.4381 - val_categorical_accuracy: 0.1765\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.3209 - categorical_accuracy: 0.8882 - val_loss: 16.4361 - val_categorical_accuracy: 0.1765\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.2724 - categorical_accuracy: 0.9145 - val_loss: 16.4368 - val_categorical_accuracy: 0.1765\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2753 - categorical_accuracy: 0.9068 - val_loss: 16.4329 - val_categorical_accuracy: 0.1765\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.2727 - categorical_accuracy: 0.9046 - val_loss: 16.4324 - val_categorical_accuracy: 0.1765\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.2794 - categorical_accuracy: 0.9046 - val_loss: 16.4416 - val_categorical_accuracy: 0.1765\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.3035 - categorical_accuracy: 0.8980 - val_loss: 16.4415 - val_categorical_accuracy: 0.1765\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2484 - categorical_accuracy: 0.9090 - val_loss: 16.4439 - val_categorical_accuracy: 0.1765\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2426 - categorical_accuracy: 0.9123 - val_loss: 16.4486 - val_categorical_accuracy: 0.1765\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2761 - categorical_accuracy: 0.9101 - val_loss: 16.4451 - val_categorical_accuracy: 0.1765\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2407 - categorical_accuracy: 0.9167 - val_loss: 16.4402 - val_categorical_accuracy: 0.1765\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2530 - categorical_accuracy: 0.9156 - val_loss: 16.4489 - val_categorical_accuracy: 0.1765\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2579 - categorical_accuracy: 0.9123 - val_loss: 16.4457 - val_categorical_accuracy: 0.1765\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2770 - categorical_accuracy: 0.9068 - val_loss: 16.4500 - val_categorical_accuracy: 0.1765\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2946 - categorical_accuracy: 0.9057 - val_loss: 16.4535 - val_categorical_accuracy: 0.1765\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2618 - categorical_accuracy: 0.9156 - val_loss: 16.4580 - val_categorical_accuracy: 0.1765\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2518 - categorical_accuracy: 0.9200 - val_loss: 16.4605 - val_categorical_accuracy: 0.1765\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2457 - categorical_accuracy: 0.9145 - val_loss: 16.4562 - val_categorical_accuracy: 0.1765\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2412 - categorical_accuracy: 0.9145 - val_loss: 16.4623 - val_categorical_accuracy: 0.1765\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2955 - categorical_accuracy: 0.9046 - val_loss: 16.4857 - val_categorical_accuracy: 0.1765\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2511 - categorical_accuracy: 0.9156 - val_loss: 16.5148 - val_categorical_accuracy: 0.1765\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2379 - categorical_accuracy: 0.9221 - val_loss: 16.5309 - val_categorical_accuracy: 0.1765\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2535 - categorical_accuracy: 0.9178 - val_loss: 16.5534 - val_categorical_accuracy: 0.1765\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2439 - categorical_accuracy: 0.9112 - val_loss: 16.5721 - val_categorical_accuracy: 0.1765\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2915 - categorical_accuracy: 0.8914 - val_loss: 16.5822 - val_categorical_accuracy: 0.1765\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2765 - categorical_accuracy: 0.9156 - val_loss: 16.5980 - val_categorical_accuracy: 0.1765\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2378 - categorical_accuracy: 0.9178 - val_loss: 16.6372 - val_categorical_accuracy: 0.1765\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2354 - categorical_accuracy: 0.9167 - val_loss: 16.6580 - val_categorical_accuracy: 0.1765\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2020 - categorical_accuracy: 0.9287 - val_loss: 16.6677 - val_categorical_accuracy: 0.1765\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2648 - categorical_accuracy: 0.9112 - val_loss: 16.6848 - val_categorical_accuracy: 0.1765\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2323 - categorical_accuracy: 0.9167 - val_loss: 16.6944 - val_categorical_accuracy: 0.1765\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.1925 - categorical_accuracy: 0.9375 - val_loss: 16.7003 - val_categorical_accuracy: 0.1765\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2419 - categorical_accuracy: 0.9211 - val_loss: 16.7169 - val_categorical_accuracy: 0.1765\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.3227 - categorical_accuracy: 0.8914 - val_loss: 16.7352 - val_categorical_accuracy: 0.1765\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2310 - categorical_accuracy: 0.9353 - val_loss: 16.7555 - val_categorical_accuracy: 0.1765\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2499 - categorical_accuracy: 0.9057 - val_loss: 16.7715 - val_categorical_accuracy: 0.1765\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2202 - categorical_accuracy: 0.9331 - val_loss: 16.7772 - val_categorical_accuracy: 0.1765\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2442 - categorical_accuracy: 0.9145 - val_loss: 16.7719 - val_categorical_accuracy: 0.1765\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2230 - categorical_accuracy: 0.9211 - val_loss: 16.7729 - val_categorical_accuracy: 0.1765\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 51ms/step - loss: 0.2133 - categorical_accuracy: 0.9243 - val_loss: 16.7615 - val_categorical_accuracy: 0.1765\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2171 - categorical_accuracy: 0.9200 - val_loss: 16.7562 - val_categorical_accuracy: 0.1765\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.2268 - categorical_accuracy: 0.9221 - val_loss: 16.7784 - val_categorical_accuracy: 0.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19514bb7b80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='categorical_accuracy', patience=10)\n",
    "transfer_model.fit(resized_image, binary_labels, epochs=50, batch_size=128, callbacks=[callback], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8e7e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: new_model_2\\assets\n"
     ]
    }
   ],
   "source": [
    "transfer_model.save(\"new_model_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a45cf9",
   "metadata": {},
   "source": [
    "# 8. Another training technique, described in Section 8.4.3 of the textbook, is data augmentation. See Section 8.2 of Deep Learning with Python, Second Edition for details.\n",
    "# How much can you improve the accuracy of the model using technique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e43115ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation layer = first layer after input\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64d6b056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 5, 5, 64)          18816     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               409856    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 27)                6939      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 435,611\n",
      "Trainable params: 435,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reconstruct a base model\n",
    "reconstructed_model_2 = tf.keras.models.load_model(\"new_model_2\")\n",
    "reconstructed_model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ca022aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model_2 = tf.keras.Sequential()\n",
    "for layer in reconstructed_model_2.layers:\n",
    "  inner_model_2.add(layer)\n",
    "\n",
    "\n",
    "# freeze\n",
    "for layer in inner_model_2.layers:\n",
    "  layer.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51a14d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 27)                435611    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               3584      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 442,678\n",
      "Trainable params: 7,067\n",
      "Non-trainable params: 435,611\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the data augmentation layer on top as the first layer\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = data_augmentation(inputs)\n",
    "x = inner_model_2(x, training=False)\n",
    "x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "transfer_model_2 = keras.Model(inputs, outputs)\n",
    "transfer_model_2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bea79dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_2.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbf0be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 58ms/step - loss: 3.2921 - categorical_accuracy: 0.0395 - val_loss: 3.3729 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 3.2753 - categorical_accuracy: 0.0746 - val_loss: 3.4201 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 3.2552 - categorical_accuracy: 0.0888 - val_loss: 3.4671 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 3.2364 - categorical_accuracy: 0.1107 - val_loss: 3.5153 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 3.2155 - categorical_accuracy: 0.1316 - val_loss: 3.5666 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 3.2012 - categorical_accuracy: 0.1305 - val_loss: 3.6213 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 3.1788 - categorical_accuracy: 0.1579 - val_loss: 3.6800 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 3.1590 - categorical_accuracy: 0.1623 - val_loss: 3.7461 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 3.1389 - categorical_accuracy: 0.1875 - val_loss: 3.8168 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 3.1203 - categorical_accuracy: 0.1908 - val_loss: 3.8896 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 3.0940 - categorical_accuracy: 0.2007 - val_loss: 3.9693 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 3.0640 - categorical_accuracy: 0.1930 - val_loss: 4.0546 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 3.0490 - categorical_accuracy: 0.1897 - val_loss: 4.1445 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 3.0112 - categorical_accuracy: 0.2018 - val_loss: 4.2376 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.9987 - categorical_accuracy: 0.1908 - val_loss: 4.3263 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 2.9770 - categorical_accuracy: 0.1985 - val_loss: 4.4156 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 2.9476 - categorical_accuracy: 0.1919 - val_loss: 4.5065 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.9217 - categorical_accuracy: 0.2018 - val_loss: 4.5934 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.8879 - categorical_accuracy: 0.2149 - val_loss: 4.6700 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.8475 - categorical_accuracy: 0.2270 - val_loss: 4.7552 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.8453 - categorical_accuracy: 0.2237 - val_loss: 4.8420 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.8147 - categorical_accuracy: 0.2259 - val_loss: 4.9265 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.8049 - categorical_accuracy: 0.2292 - val_loss: 5.0086 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.7927 - categorical_accuracy: 0.2072 - val_loss: 5.0876 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.7812 - categorical_accuracy: 0.2050 - val_loss: 5.1689 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 2.7708 - categorical_accuracy: 0.2182 - val_loss: 5.2322 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.7451 - categorical_accuracy: 0.2160 - val_loss: 5.3037 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.7186 - categorical_accuracy: 0.2171 - val_loss: 5.3761 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 2.7130 - categorical_accuracy: 0.2237 - val_loss: 5.4225 - val_categorical_accuracy: 0.1569\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.6848 - categorical_accuracy: 0.2357 - val_loss: 5.4608 - val_categorical_accuracy: 0.1667\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 2.6958 - categorical_accuracy: 0.2171 - val_loss: 5.5162 - val_categorical_accuracy: 0.1667\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 2.6446 - categorical_accuracy: 0.2533 - val_loss: 5.5714 - val_categorical_accuracy: 0.1667\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6689 - categorical_accuracy: 0.2237 - val_loss: 5.6294 - val_categorical_accuracy: 0.1765\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6494 - categorical_accuracy: 0.2149 - val_loss: 5.6785 - val_categorical_accuracy: 0.1765\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 2.6414 - categorical_accuracy: 0.2303 - val_loss: 5.7358 - val_categorical_accuracy: 0.1765\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6555 - categorical_accuracy: 0.2292 - val_loss: 5.7892 - val_categorical_accuracy: 0.1765\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6133 - categorical_accuracy: 0.2336 - val_loss: 5.8377 - val_categorical_accuracy: 0.1765\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.6398 - categorical_accuracy: 0.2314 - val_loss: 5.8752 - val_categorical_accuracy: 0.1765\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.6362 - categorical_accuracy: 0.2160 - val_loss: 5.9185 - val_categorical_accuracy: 0.1765\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6107 - categorical_accuracy: 0.2248 - val_loss: 5.9500 - val_categorical_accuracy: 0.1765\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6370 - categorical_accuracy: 0.2127 - val_loss: 5.9812 - val_categorical_accuracy: 0.1765\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.6351 - categorical_accuracy: 0.2039 - val_loss: 6.0227 - val_categorical_accuracy: 0.1765\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5840 - categorical_accuracy: 0.2270 - val_loss: 6.0685 - val_categorical_accuracy: 0.1765\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5994 - categorical_accuracy: 0.2138 - val_loss: 6.1077 - val_categorical_accuracy: 0.1765\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 2.6053 - categorical_accuracy: 0.2127 - val_loss: 6.1504 - val_categorical_accuracy: 0.1765\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5396 - categorical_accuracy: 0.2577 - val_loss: 6.1838 - val_categorical_accuracy: 0.1765\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5719 - categorical_accuracy: 0.2357 - val_loss: 6.2269 - val_categorical_accuracy: 0.1765\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 2.5749 - categorical_accuracy: 0.2204 - val_loss: 6.2671 - val_categorical_accuracy: 0.1765\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.6402 - categorical_accuracy: 0.2193 - val_loss: 6.3081 - val_categorical_accuracy: 0.1765\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 44ms/step - loss: 2.5751 - categorical_accuracy: 0.2379 - val_loss: 6.3384 - val_categorical_accuracy: 0.1765\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.5661 - categorical_accuracy: 0.2281 - val_loss: 6.3681 - val_categorical_accuracy: 0.1765\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5852 - categorical_accuracy: 0.2314 - val_loss: 6.3975 - val_categorical_accuracy: 0.1765\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5840 - categorical_accuracy: 0.2368 - val_loss: 6.4352 - val_categorical_accuracy: 0.1765\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 38ms/step - loss: 2.5749 - categorical_accuracy: 0.2292 - val_loss: 6.4729 - val_categorical_accuracy: 0.1765\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5391 - categorical_accuracy: 0.2412 - val_loss: 6.4988 - val_categorical_accuracy: 0.1765\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5782 - categorical_accuracy: 0.2303 - val_loss: 6.5320 - val_categorical_accuracy: 0.1765\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5820 - categorical_accuracy: 0.2314 - val_loss: 6.5673 - val_categorical_accuracy: 0.1765\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5753 - categorical_accuracy: 0.2237 - val_loss: 6.5908 - val_categorical_accuracy: 0.1765\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 2.5255 - categorical_accuracy: 0.2445 - val_loss: 6.6203 - val_categorical_accuracy: 0.1765\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5207 - categorical_accuracy: 0.2325 - val_loss: 6.6527 - val_categorical_accuracy: 0.1765\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 2.5535 - categorical_accuracy: 0.2357 - val_loss: 6.6789 - val_categorical_accuracy: 0.1765\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5529 - categorical_accuracy: 0.2226 - val_loss: 6.6915 - val_categorical_accuracy: 0.1765\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 43ms/step - loss: 2.6045 - categorical_accuracy: 0.2083 - val_loss: 6.7110 - val_categorical_accuracy: 0.1765\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.5196 - categorical_accuracy: 0.2456 - val_loss: 6.7239 - val_categorical_accuracy: 0.1765\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.6110 - categorical_accuracy: 0.2248 - val_loss: 6.7345 - val_categorical_accuracy: 0.1765\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5071 - categorical_accuracy: 0.2456 - val_loss: 6.7596 - val_categorical_accuracy: 0.1765\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 2.5248 - categorical_accuracy: 0.2412 - val_loss: 6.7984 - val_categorical_accuracy: 0.1765\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5578 - categorical_accuracy: 0.2401 - val_loss: 6.8329 - val_categorical_accuracy: 0.1765\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5673 - categorical_accuracy: 0.2094 - val_loss: 6.8560 - val_categorical_accuracy: 0.1765\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 2.5699 - categorical_accuracy: 0.2083 - val_loss: 6.8760 - val_categorical_accuracy: 0.1765\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.4901 - categorical_accuracy: 0.2577 - val_loss: 6.8986 - val_categorical_accuracy: 0.1765\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5531 - categorical_accuracy: 0.2259 - val_loss: 6.9306 - val_categorical_accuracy: 0.1765\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.4804 - categorical_accuracy: 0.2489 - val_loss: 6.9600 - val_categorical_accuracy: 0.1765\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5025 - categorical_accuracy: 0.2522 - val_loss: 6.9663 - val_categorical_accuracy: 0.1765\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5585 - categorical_accuracy: 0.2281 - val_loss: 6.9706 - val_categorical_accuracy: 0.1765\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 2.5369 - categorical_accuracy: 0.2226 - val_loss: 6.9864 - val_categorical_accuracy: 0.1765\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 2.5327 - categorical_accuracy: 0.2379 - val_loss: 7.0072 - val_categorical_accuracy: 0.1765\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5060 - categorical_accuracy: 0.2270 - val_loss: 7.0391 - val_categorical_accuracy: 0.1765\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5421 - categorical_accuracy: 0.2281 - val_loss: 7.0788 - val_categorical_accuracy: 0.1765\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.5399 - categorical_accuracy: 0.2292 - val_loss: 7.1155 - val_categorical_accuracy: 0.1765\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 2.5127 - categorical_accuracy: 0.2478 - val_loss: 7.1350 - val_categorical_accuracy: 0.1765\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5378 - categorical_accuracy: 0.2434 - val_loss: 7.1469 - val_categorical_accuracy: 0.1765\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 2.5586 - categorical_accuracy: 0.2423 - val_loss: 7.1630 - val_categorical_accuracy: 0.1765\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5651 - categorical_accuracy: 0.2193 - val_loss: 7.1790 - val_categorical_accuracy: 0.1765\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5127 - categorical_accuracy: 0.2292 - val_loss: 7.1996 - val_categorical_accuracy: 0.1765\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.5445 - categorical_accuracy: 0.2237 - val_loss: 7.2177 - val_categorical_accuracy: 0.1765\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5606 - categorical_accuracy: 0.2226 - val_loss: 7.2220 - val_categorical_accuracy: 0.1765\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5425 - categorical_accuracy: 0.2270 - val_loss: 7.2373 - val_categorical_accuracy: 0.1765\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5062 - categorical_accuracy: 0.2401 - val_loss: 7.2526 - val_categorical_accuracy: 0.1765\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 39ms/step - loss: 2.5168 - categorical_accuracy: 0.2500 - val_loss: 7.2637 - val_categorical_accuracy: 0.1765\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5256 - categorical_accuracy: 0.2204 - val_loss: 7.2937 - val_categorical_accuracy: 0.1765\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5402 - categorical_accuracy: 0.2171 - val_loss: 7.3100 - val_categorical_accuracy: 0.1765\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5794 - categorical_accuracy: 0.2160 - val_loss: 7.3346 - val_categorical_accuracy: 0.1765\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5122 - categorical_accuracy: 0.2248 - val_loss: 7.3424 - val_categorical_accuracy: 0.1765\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 42ms/step - loss: 2.5370 - categorical_accuracy: 0.2325 - val_loss: 7.3382 - val_categorical_accuracy: 0.1765\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 2.5336 - categorical_accuracy: 0.2346 - val_loss: 7.3461 - val_categorical_accuracy: 0.1765\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 41ms/step - loss: 2.5040 - categorical_accuracy: 0.2412 - val_loss: 7.3616 - val_categorical_accuracy: 0.1765\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5424 - categorical_accuracy: 0.2314 - val_loss: 7.3774 - val_categorical_accuracy: 0.1765\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 2.5537 - categorical_accuracy: 0.2215 - val_loss: 7.4004 - val_categorical_accuracy: 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 40ms/step - loss: 2.5090 - categorical_accuracy: 0.2412 - val_loss: 7.4290 - val_categorical_accuracy: 0.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1951cdeffd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "transfer_model_2.fit(resized_image, binary_labels, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fb54aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 27)                435611    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               3584      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 27)                3483      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 442,678\n",
      "Trainable params: 442,678\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# unfreeze\n",
    "inner_model_2.trainable=True\n",
    "transfer_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ceef86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model_2.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdc96547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 2.4880 - categorical_accuracy: 0.2423 - val_loss: 7.4325 - val_categorical_accuracy: 0.1765\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 2.4681 - categorical_accuracy: 0.2423 - val_loss: 7.4352 - val_categorical_accuracy: 0.1765\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 2.4766 - categorical_accuracy: 0.2368 - val_loss: 7.4376 - val_categorical_accuracy: 0.1765\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 2.4498 - categorical_accuracy: 0.2522 - val_loss: 7.4395 - val_categorical_accuracy: 0.1765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19518f670d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "transfer_model_2.fit(resized_image, binary_labels, epochs=30, batch_size=128, callbacks=[callback], validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc576cc6",
   "metadata": {},
   "source": [
    "## A: Via data augmentation, we extended the small dataset to contain a wider variety of sample data, which decreases the ability of the model to simply memorize the training data. As a result, we see the training accuracy drop to become much closer to the validation accuracy, indicating that the model is no longer overfitting to the training data and will be better at generalizing. The improved generalization ability is reflected in the increased validation accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
