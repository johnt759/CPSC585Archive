{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa7e63f",
   "metadata": {},
   "source": [
    "# Spring 2022\n",
    "# CPSC 585 Project 4\n",
    "## Raymond Carpio\n",
    "## Yu Pan\n",
    "## Sijie Shang\n",
    "## John Tu\n",
    "\n",
    "### Based on the example from TensorFlow's RNN text generation:\n",
    "### https://www.tensorflow.org/text/tutorials/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d6e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following modules over\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Try to open the text file if it exists.\n",
    "input_file = \"infinity-war.txt\"\n",
    "corpus_raw = open(input_file, \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "# Print out the sample text file.\n",
    "#print(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deeff9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '%', '&', \"'\", ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '’', '…']\n",
      "Total length of text:  60487\n",
      "Total number of characters found:  77\n"
     ]
    }
   ],
   "source": [
    "# Obtain the list of characters included in the raw text.\n",
    "# Be sure to use set() to filter out duplicates.\n",
    "characters = sorted(list(set(corpus_raw)))\n",
    "\n",
    "# Print out the list of characters found in the raw text.\n",
    "print(characters)\n",
    "\n",
    "# Also obtain the total length of the text and the characters.\n",
    "print(\"Total length of text: \", len(corpus_raw))\n",
    "print(\"Total number of characters found: \", len(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84fbbc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Asgardian PA: This is the Asgardian refugee vessel Statesman. We are under assault, I repeat, we are under assault - The engines are dead, life support failing. Requesting aid from any vessel within range. We are 22 jump points out of Asgard.  Our crew is made up of Asgardian families, we have very few soldiers here. This is not a warcraft. I repeat, this is not a warcraft!\n",
      "\n",
      "\n",
      "\n",
      "Ebony Maw: Hear me, and rejoice. You have had the privilege of being saved by the Great Titan... You may think this \n"
     ]
    }
   ],
   "source": [
    "# Print out the first 500 characters of the text.\n",
    "print(corpus_raw[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f95f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
       " [b'w', b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the text by converting the string into a numerical form.\n",
    "sample_text = ['abcdefghij', 'wxyz']\n",
    "num_chars = tf.strings.unicode_split(sample_text, input_encoding=\"UTF-8\")\n",
    "num_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9a2dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59], [72, 73, 74, 75]]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_from_characters = tf.keras.layers.StringLookup(vocabulary=list(characters))\n",
    "ids = id_from_characters(num_chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e877107f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
       " [b'w', b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_from_id = tf.keras.layers.StringLookup(vocabulary=id_from_characters.get_vocabulary(), invert=True)\n",
    "characters = characters_from_id(ids)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f827c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the corresponding string ids back into text form.\n",
    "def text_from_id(ids):\n",
    "    return tf.strings.reduce_join(characters_from_id(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4db834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60487,), dtype=int64, numpy=array([ 1,  1,  1, ..., 10,  1,  1], dtype=int64)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_id = id_from_characters(tf.strings.unicode_split(corpus_raw, 'UTF-8'))\n",
    "all_text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b96fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A\n",
      "s\n",
      "g\n",
      "a\n",
      "r\n",
      "d\n",
      "i\n",
      "a\n",
      "n\n",
      " \n",
      "P\n",
      "A\n",
      ":\n",
      " \n",
      "T\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "# Try to print out the first 25 characters from raw text via tensor slices.\n",
    "id_dataset = tf.data.Dataset.from_tensor_slices(all_text_id)\n",
    "for curr_id in id_dataset.take(25):\n",
    "    print(characters_from_id(curr_id).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d763d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\\n' b'\\n' b'\\n' b'\\n' b'A' b's' b'g' b'a' b'r' b'd' b'i' b'a' b'n' b' '\n",
      " b'P' b'A' b':' b' ' b'T' b'h' b'i' b's' b' ' b'i' b's' b' ' b't' b'h'\n",
      " b'e' b' ' b'A' b's' b'g' b'a' b'r' b'd' b'i' b'a' b'n' b' ' b'r' b'e'\n",
      " b'f' b'u' b'g' b'e' b'e' b' ' b'v' b'e' b's' b's' b'e' b'l' b' ' b'S'\n",
      " b't' b'a' b't' b'e' b's' b'm' b'a' b'n' b'.' b' ' b'W' b'e' b' ' b'a'\n",
      " b'r' b'e' b' ' b'u' b'n' b'd' b'e' b'r' b' ' b'a' b's' b's' b'a' b'u'\n",
      " b'l' b't' b',' b' ' b'I' b' ' b'r' b'e' b'p' b'e' b'a' b't' b',' b' '\n",
      " b'w' b'e' b' ' b'a' b'r' b'e' b' ' b'u' b'n' b'd' b'e' b'r' b' ' b'a'\n",
      " b's' b's' b'a' b'u' b'l' b't' b' ' b'-' b' ' b'T' b'h' b'e' b' ' b'e'\n",
      " b'n' b'g' b'i' b'n' b'e' b's' b' ' b'a' b'r' b'e' b' ' b'd' b'e' b'a'\n",
      " b'd' b',' b' ' b'l' b'i' b'f' b'e' b' ' b's' b'u' b'p'], shape=(151,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Now build a sequence of the first 150 characters.\n",
    "sequence_len = 150\n",
    "each_example = len(corpus_raw)\n",
    "sequences = id_dataset.batch(sequence_len+1, drop_remainder=True)\n",
    "\n",
    "for curr_seq in sequences.take(1):\n",
    "    print(characters_from_id(curr_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d9eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\n\\n\\nAsgardian PA: This is the Asgardian refugee vessel Statesman. We are under assault, I repeat, we are under assault - The engines are dead, life sup'\n",
      "b'port failing. Requesting aid from any vessel within range. We are 22 jump points out of Asgard.  Our crew is made up of Asgardian families, we have ver'\n",
      "b'y few soldiers here. This is not a warcraft. I repeat, this is not a warcraft!\\n\\n\\n\\nEbony Maw: Hear me, and rejoice. You have had the privilege of being '\n",
      "b'saved by the Great Titan... You may think this is suffering... No. it is salvation. Universal scales tip toward balance because of your sacrifice. Smil'\n",
      "b\"e...  For even in death, you have become Children of Thanos.\\n\\n\\n\\nThanos:  I know what it's like to lose. To feel so desperately that you're right... yet\"\n"
     ]
    }
   ],
   "source": [
    "for curr_seq in sequences.take(5):\n",
    "    print(text_from_id(curr_seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8ca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f1dcb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  b'\\n\\n\\n\\nAsgardian PA: This is the Asgardian refugee vessel Statesman. We are under assault, I repeat, we are under assault - The engines are dead, life su'\n",
      "Target:  b'\\n\\n\\nAsgardian PA: This is the Asgardian refugee vessel Statesman. We are under assault, I repeat, we are under assault - The engines are dead, life sup'\n"
     ]
    }
   ],
   "source": [
    "text_dataset = sequences.map(split_target)\n",
    "for input_text, target_text in text_dataset.take(1):\n",
    "    print(\"Input: \", text_from_id(input_text).numpy())\n",
    "    print(\"Target: \", text_from_id(target_text).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc4123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 150), dtype=tf.int64, name=None), TensorSpec(shape=(64, 150), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    text_dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1a31270",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(corpus_raw))\n",
    "vocab_size = len(vocab)\n",
    "embedding_dimension=256\n",
    "rnn_units=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c5f1602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc273d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(id_from_characters.get_vocabulary()),\n",
    "    embedding_dim=embedding_dimension,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceda7e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 150, 78) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a620c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  19968     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  79950     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,038,222\n",
      "Trainable params: 4,038,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64b7c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 24, 19, 13, 48, 16, 70, 66, 74, 22, 57, 14, 34, 38, 39, 59, 12,\n",
       "       33, 53, 75, 39, 70, 11, 55, 37, 28, 45, 63, 71, 68, 64, 26, 18, 29,\n",
       "       54, 55,  6, 54,  4, 72, 22, 52, 17,  0, 53, 34, 52, 49, 70, 38, 11,\n",
       "       71, 63, 16, 36,  3,  3, 48, 36,  3, 24,  0, 27, 40,  5, 31, 59, 76,\n",
       "       68, 61, 20, 74, 53,  0, 49, 66, 55, 10, 10, 57, 28, 27, 11, 40, 61,\n",
       "       48, 73, 34, 60, 27, 54, 29, 21, 16, 47,  0,  5, 54, 56, 20, 17, 39,\n",
       "       49,  0, 20, 28, 27, 49,  4, 59,  1, 57, 58, 37, 74, 49, 55, 67, 12,\n",
       "       13, 25, 71,  2, 29,  0,  4, 69, 61, 69, 55, 51, 50, 53, 44, 31, 13,\n",
       "       37, 16, 49, 56, 48, 16, 40, 61, 52, 41, 71, 27,  8, 16],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd28ae2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b' these dwarves are better at forging than they are cleaning. Maybe they realized they live in a junk pile in the middle of space.\\n\\nThor: This forge ha'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'\\nB71Z4uqy?h2LPQj0KdzQu.fOFWnvsoD6Gef&e\"w?c5[UNK]dLc]uP.vn4N!!ZN!B[UNK]ER%Ij\\xe2\\x80\\x99sl8yd[UNK]]qf--hFE.RlZxLkEeG:4Y[UNK]%eg85Q][UNK]8FE]\"j\\nhiOy]fr01Cv G[UNK]\"tltfbadVI1O4]gZ4RlcSvE)4'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_id(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_id(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a0dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 150, 78)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.356975, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.02077"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)\n",
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce32c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efce84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 22s 3s/step - loss: 4.9595\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 20s 3s/step - loss: 4.1037\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 21s 4s/step - loss: 3.9537\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 24s 4s/step - loss: 3.5004\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 3.2321\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 3.1338\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 24s 4s/step - loss: 3.0262\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 25s 4s/step - loss: 2.9156\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 23s 4s/step - loss: 2.7912\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 24s 4s/step - loss: 2.6704\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 24s 4s/step - loss: 2.5789\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 24s 4s/step - loss: 2.5107\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 26s 4s/step - loss: 2.4521\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 26s 4s/step - loss: 2.4055\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 2.3632\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 2.3249\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 29s 5s/step - loss: 2.2873\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 27s 4s/step - loss: 2.2600\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 26s 4s/step - loss: 2.2272\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 27s 5s/step - loss: 2.1936\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 2.1647\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 2.1308\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 2.0938\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 2.0658\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 27s 4s/step - loss: 2.0281\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 29s 5s/step - loss: 2.0012\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 1.9630\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 28s 5s/step - loss: 1.9331\n",
      "Epoch 29/30\n",
      "3/6 [==============>...............] - ETA: 12s - loss: 1.9195"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=30, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de07f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, characters_from_id, id_from_characters, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39697abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['This'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504b009",
   "metadata": {},
   "source": [
    "## If there are modifications made for this code, then it would be the length of the example sequence for input text processing and the number of epochs to run for training. Also, the changes made so far are the example text vector and the temperature parameter for the one-step RNN model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a250a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
