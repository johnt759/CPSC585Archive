{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "caa7e63f",
      "metadata": {
        "id": "caa7e63f"
      },
      "source": [
        "# Spring 2022\n",
        "# CPSC 585 Project 4\n",
        "## Raymond Carpio\n",
        "## Yu Pan\n",
        "## Sijie Shang\n",
        "## John Tu\n",
        "\n",
        "### Based on the example from Tensorflow's text generation with RNN:\n",
        "### https://www.tensorflow.org/text/tutorials/text_generation\n",
        "\n",
        "### Text used for the RNN model: The entire script from Lord of the Rings: Fellowship of the Ring"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changes made to the code:\n",
        "## If there are modifications made for this code, then it would be the length of the example sequence for input text processing and the number of epochs to run for training. Also, the changes made so far are the example text vector and the temperature parameter for the one-step RNN model class."
      ],
      "metadata": {
        "id": "VvtJIZtltUA2"
      },
      "id": "VvtJIZtltUA2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d6e219",
      "metadata": {
        "id": "a4d6e219"
      },
      "outputs": [],
      "source": [
        "# Import the following modules over\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Try to open the text file if it exists.\n",
        "input_file = \"rings.txt\"\n",
        "corpus_raw = open(input_file, \"r\", encoding=\"utf-8\").read()\n",
        "\n",
        "# Print out the sample text file.\n",
        "#print(corpus_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deeff9dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deeff9dc",
        "outputId": "36befb88-c2c4-40d5-b9b3-f2a0646bbbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Ó', 'á', 'â', 'ä', 'é', 'ë', 'í', 'ó', 'ú', 'û', '–']\n",
            "Total length of text:  1021058\n",
            "Total number of characters found:  90\n"
          ]
        }
      ],
      "source": [
        "# Obtain the list of characters included in the raw text.\n",
        "# Be sure to use set() to filter out duplicates.\n",
        "characters = sorted(list(set(corpus_raw)))\n",
        "\n",
        "# Print out the list of characters found in the raw text.\n",
        "print(characters)\n",
        "\n",
        "# Also obtain the total length of the text and the characters.\n",
        "print(\"Total length of text: \", len(corpus_raw))\n",
        "print(\"Total number of characters found: \", len(characters))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fbbc7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84fbbc7b",
        "outputId": "abec4ed2-9970-4835-c198-c99136317e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Three Rings for the Elven-kings under the sky,\n",
            "               Seven for the Dwarf-lords in their halls of stone,\n",
            "            Nine for Mortal Men doomed to die,\n",
            "              One for the Dark Lord on his dark throne\n",
            "           In the Land of Mordor where the Shadows lie.\n",
            "               One Ring to rule them all, One Ring to find them,\n",
            "               One Ring to bring them all and in the darkness bind them\n",
            "           In the Land of Mordor where the Shadows lie.\n",
            "           \n",
            "FOREWORD\n",
            "\n",
            "This tale grew\n"
          ]
        }
      ],
      "source": [
        "# Print out the first 500 characters of the text.\n",
        "print(corpus_raw[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f95f52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11f95f52",
        "outputId": "a1e92efa-821c-487f-d78b-9e2fe786d0a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
              " [b'w', b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Vectorize the text by converting the string into a numerical form.\n",
        "sample_text = ['abcdefghij', 'wxyz']\n",
        "num_chars = tf.strings.unicode_split(sample_text, input_encoding=\"UTF-8\")\n",
        "num_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9a2dbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9a2dbe",
        "outputId": "76977837-1988-4873-8f28-dea9685c8dc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[54, 55, 56, 57, 58, 59, 60, 61, 62, 63], [76, 77, 78, 79]]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "id_from_characters = tf.keras.layers.StringLookup(vocabulary=list(characters))\n",
        "ids = id_from_characters(num_chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e877107f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e877107f",
        "outputId": "5b4d4295-bff5-4c78-c306-ddc0da51ca3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j'],\n",
              " [b'w', b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "characters_from_id = tf.keras.layers.StringLookup(vocabulary=id_from_characters.get_vocabulary(), invert=True)\n",
        "characters = characters_from_id(ids)\n",
        "characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f827c832",
      "metadata": {
        "id": "f827c832"
      },
      "outputs": [],
      "source": [
        "# Convert the corresponding string ids back into text form.\n",
        "def text_from_id(ids):\n",
        "    return tf.strings.reduce_join(characters_from_id(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4db834",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a4db834",
        "outputId": "1a1207b1-1166-4702-d10a-d927b777f250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1021058,), dtype=int64, numpy=array([45, 61, 71, ..., 32, 10,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "all_text_id = id_from_characters(tf.strings.unicode_split(corpus_raw, 'UTF-8'))\n",
        "all_text_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31b96fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31b96fde",
        "outputId": "38571071-20cc-428a-8027-3411a2b5771b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "h\n",
            "r\n",
            "e\n",
            "e\n",
            " \n",
            "R\n",
            "i\n",
            "n\n",
            "g\n",
            "s\n",
            " \n",
            "f\n",
            "o\n",
            "r\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "E\n",
            "l\n",
            "v\n",
            "e\n",
            "n\n"
          ]
        }
      ],
      "source": [
        "# Try to print out the first 25 characters from raw text via tensor slices.\n",
        "id_dataset = tf.data.Dataset.from_tensor_slices(all_text_id)\n",
        "for curr_id in id_dataset.take(25):\n",
        "    print(characters_from_id(curr_id).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d763d8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d763d8c",
        "outputId": "1b7ff064-5d79-4428-a220-3e5801395e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'T' b'h' b'r' b'e' b'e' b' ' b'R' b'i' b'n' b'g' b's' b' ' b'f' b'o'\n",
            " b'r' b' ' b't' b'h' b'e' b' ' b'E' b'l' b'v' b'e' b'n' b'-' b'k' b'i'\n",
            " b'n' b'g' b's' b' ' b'u' b'n' b'd' b'e' b'r' b' ' b't' b'h' b'e' b' '\n",
            " b's' b'k' b'y' b',' b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
            " b' ' b' ' b' ' b' ' b' ' b' ' b'S' b'e' b'v' b'e' b'n' b' ' b'f' b'o'\n",
            " b'r' b' ' b't' b'h' b'e' b' ' b'D' b'w' b'a' b'r' b'f' b'-' b'l' b'o'\n",
            " b'r' b'd' b's' b' ' b'i' b'n' b' ' b't' b'h' b'e' b'i' b'r' b' ' b'h'\n",
            " b'a' b'l' b'l' b's' b' ' b'o' b'f' b' ' b's' b't' b'o' b'n' b'e' b','\n",
            " b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b'N'\n",
            " b'i' b'n' b'e' b' ' b'f' b'o' b'r' b' ' b'M' b'o' b'r' b't' b'a' b'l'\n",
            " b' ' b'M' b'e' b'n' b' ' b'd' b'o' b'o' b'm' b'e' b'd' b' ' b't' b'o'\n",
            " b' ' b'd' b'i' b'e' b',' b'\\n' b' ' b' ' b' ' b' ' b' ' b' ' b' ' b' '\n",
            " b' ' b' ' b' ' b' ' b' ' b' ' b'O' b'n' b'e' b' ' b'f' b'o' b'r' b' '\n",
            " b't' b'h' b'e' b' ' b'D' b'a' b'r' b'k' b' ' b'L' b'o' b'r' b'd' b' '\n",
            " b'o' b'n' b' ' b'h' b'i'], shape=(201,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Now build a sequence of the first 200 characters.\n",
        "sequence_len = 200\n",
        "each_example = len(corpus_raw)\n",
        "sequences = id_dataset.batch(sequence_len+1, drop_remainder=True)\n",
        "\n",
        "for curr_seq in sequences.take(1):\n",
        "    print(characters_from_id(curr_seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d9eaa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5d9eaa7",
        "outputId": "94451897-6c57-467e-b109-c4cafae62275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Three Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on hi'\n",
            "b's dark throne\\n           In the Land of Mordor where the Shadows lie.\\n               One Ring to rule them all, One Ring to find them,\\n               One Ring to bring them all and in the darkness bind'\n",
            "b' them\\n           In the Land of Mordor where the Shadows lie.\\n           \\nFOREWORD\\n\\nThis tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses of t'\n",
            "b'he yet more ancient history that preceded it. It was begun soon after _The Hobbit_ was written and before its publication in 1937; but I did not go on with this sequel, for I wished first to complete a'\n",
            "b'nd set in order the mythology and legends of the Elder Days, which had then been taking shape for some years. I desired to do this for my own satisfaction, and I had little hope that other people would'\n"
          ]
        }
      ],
      "source": [
        "for curr_seq in sequences.take(5):\n",
        "    print(text_from_id(curr_seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8ca678",
      "metadata": {
        "id": "cd8ca678"
      },
      "outputs": [],
      "source": [
        "def split_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f1dcb43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f1dcb43",
        "outputId": "9ba0f4e0-067e-4e66-fc6d-da9cbcdc1432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  b'Three Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on h'\n",
            "Target:  b'hree Rings for the Elven-kings under the sky,\\n               Seven for the Dwarf-lords in their halls of stone,\\n            Nine for Mortal Men doomed to die,\\n              One for the Dark Lord on hi'\n"
          ]
        }
      ],
      "source": [
        "text_dataset = sequences.map(split_target)\n",
        "for input_text, target_text in text_dataset.take(1):\n",
        "    print(\"Input: \", text_from_id(input_text).numpy())\n",
        "    print(\"Target: \", text_from_id(target_text).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afc4123e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afc4123e",
        "outputId": "82edab87-c354-48ac-96c4-c42636655c3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 200), dtype=tf.int64, name=None), TensorSpec(shape=(64, 200), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    text_dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a31270",
      "metadata": {
        "id": "b1a31270"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(corpus_raw))\n",
        "vocab_size = len(vocab)\n",
        "embedding_dimension=256\n",
        "rnn_units=1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5f1602",
      "metadata": {
        "id": "0c5f1602"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc273d46",
      "metadata": {
        "id": "dc273d46"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(id_from_characters.get_vocabulary()),\n",
        "    embedding_dim=embedding_dimension,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceda7e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceda7e97",
        "outputId": "90f0c8ac-981d-454e-bbaa-b3a9207c8dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 200, 91) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a620c25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a620c25",
        "outputId": "03eaec47-2ba5-4bcf-c943-f7916b9db793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  23296     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  93275     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,054,875\n",
            "Trainable params: 4,054,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e64b7c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e64b7c35",
        "outputId": "67e75afa-55e5-4e1d-9ac3-f974777d02b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([61, 31, 72, 70,  3, 63, 46, 24, 70, 43, 13, 56, 79, 62, 72, 81, 51,\n",
              "       86, 44, 30, 67, 89,  9,  2, 65,  4, 58, 41, 60, 78, 19, 59, 31, 50,\n",
              "       60, 50, 16, 63, 22, 44, 30,  1, 61, 27,  8,  3, 87, 82,  5, 88, 37,\n",
              "       27, 22, 87, 32, 65, 34, 56, 47, 44, 60,  6,  8, 69, 24, 34, 30, 86,\n",
              "        1, 59, 36, 37,  3,  1, 33,  5, 87, 32,  9,  4, 27, 36, 36, 68,  5,\n",
              "       18, 64, 40, 55, 56, 54, 13, 76, 25, 78, 12, 41, 31,  7, 88, 58, 55,\n",
              "       55, 36, 80, 59, 44, 90, 46, 31, 67, 57, 89, 13, 76, 51, 42,  7, 25,\n",
              "       16, 31, 54, 34, 50, 64, 59, 56, 42, 84, 17, 18, 53, 32, 21, 49, 62,\n",
              "       11, 46, 62, 65, 58, 30, 20,  8, 84, 49, 20, 58, 46, 39,  7, 46, 88,\n",
              "       10, 64, 41, 34, 45, 76, 32, 59, 75, 16, 78, 61, 43, 30, 89, 44, 64,\n",
              "       39, 35, 32, 15, 89, 23, 21, 84, 32, 15, 53, 31, 16, 33, 86, 41, 13,\n",
              "        4,  6, 62, 32, 17, 24, 38, 37, 83, 55, 39, 76, 22])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd28ae2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd28ae2f",
        "outputId": "4465992c-e87d-4cc3-9fa0-f09df3e16e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'  _Chapter 2_\\n            The Shadow of the Past\\n\\n     The talk did not die down in nine or even ninety-nine days. The second disappearance of Mr. Bilbo Baggins was discussed in Hobbiton, and indeed a'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'hFsq!jU=qR1czis\\xc3\\xa1Z\\xc3\\xadSEn\\xc3\\xbb- l\"ePgy7fFYgY4j:SE\\nhB,!\\xc3\\xb3\\xc3\\xa2\\'\\xc3\\xbaLB:\\xc3\\xb3GlIcVSg(,p=IE\\xc3\\xad\\nfKL!\\nH\\'\\xc3\\xb3G-\"BKKo\\'6kObca1w?y0PF)\\xc3\\xbaebbK\\xc3\\x93fS\\xe2\\x80\\x93UFnd\\xc3\\xbb1wZQ)?4FaIYkfcQ\\xc3\\xa956`G9Xi/UileE8,\\xc3\\xa9X8eUN)U\\xc3\\xba.kPITwGfv4yhRE\\xc3\\xbbSkNJG3\\xc3\\xbb;9\\xc3\\xa9G3`F4H\\xc3\\xadP1\"(iG5=ML\\xc3\\xa4bNw:'\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_id(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_id(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a0dd09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06a0dd09",
        "outputId": "05ac871f-5e6f-4cb2-acb0-54eeab89df2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 200, 91)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.5113063, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91.04067"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce32c023",
      "metadata": {
        "id": "ce32c023"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efce84d2",
      "metadata": {
        "id": "efce84d2"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9a6a87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9a6a87",
        "outputId": "9d52d23b-dcbb-4e78-ca83-b79338a21450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "79/79 [==============================] - 10s 92ms/step - loss: 3.0312\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 8s 91ms/step - loss: 2.2180\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 8s 91ms/step - loss: 1.9455\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 8s 92ms/step - loss: 1.7320\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 8s 93ms/step - loss: 1.5665\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 9s 94ms/step - loss: 1.4466\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 9s 94ms/step - loss: 1.3598\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 9s 95ms/step - loss: 1.2953\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 9s 95ms/step - loss: 1.2432\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 9s 95ms/step - loss: 1.2019\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 9s 96ms/step - loss: 1.1649\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 9s 96ms/step - loss: 1.1322\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 9s 96ms/step - loss: 1.1023\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 9s 97ms/step - loss: 1.0730\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 9s 97ms/step - loss: 1.0455\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 9s 97ms/step - loss: 1.0178\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 9s 97ms/step - loss: 0.9882\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 9s 98ms/step - loss: 0.9599\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.9298\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 9s 97ms/step - loss: 0.8989\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.8670\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.8345\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 9s 98ms/step - loss: 0.8013\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 9s 98ms/step - loss: 0.7649\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.7272\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.6906\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 9s 99ms/step - loss: 0.6545\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.6183\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.5813\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.5472\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.5143\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.4841\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.4566\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.4288\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.4046\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.3831\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.3670\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.3509\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.3316\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.3197\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.3093\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2957\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2828\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2732\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2664\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2616\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2525\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.2465\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2395\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2344\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2299\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.2268\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2203\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2158\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 9s 100ms/step - loss: 0.2148\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2098\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2101\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2096\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2069\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2034\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.2030\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2015\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.2014\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2024\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2026\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2004\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1952\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1944\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1903\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1850\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1819\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1763\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1732\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1699\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1687\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1692\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1756\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1834\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1941\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2039\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2077\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2123\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2115\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2079\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1991\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1888\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1788\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1714\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1604\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1520\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1443\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1365\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1307\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1264\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1256\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1291\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1373\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.1553\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 9s 102ms/step - loss: 0.1857\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 9s 101ms/step - loss: 0.2399\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=100, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6de07f8e",
      "metadata": {
        "id": "6de07f8e"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa6c831",
      "metadata": {
        "id": "0aa6c831"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, characters_from_id, id_from_characters, 1.0)\n",
        "one_step_model1 = OneStep(model, characters_from_id, id_from_characters, 0.9)\n",
        "one_step_model2 = OneStep(model, characters_from_id, id_from_characters, 0.8)\n",
        "one_step_model3 = OneStep(model, characters_from_id, id_from_characters, 0.7)\n",
        "one_step_model4 = OneStep(model, characters_from_id, id_from_characters, 0.6)\n",
        "one_step_model5 = OneStep(model, characters_from_id, id_from_characters, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39697abc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39697abc",
        "outputId": "e47339ae-79e1-462e-ca73-dffe0f995166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was a sound of munning eastwards behind, or halfling now to make loss lands for them:\n",
            "     There were no power over the mountains of Saruman dimly into the touch for many times; but the wind in the familiest standing stone like step forward. In the dear of the reperth ninety ninet, they ming, free for the outching through the lowly into a deeply drum-beat:\n",
            "     Then he would not slipping flask and asked to wait. 'That is the way for us,' said Gimli.\n",
            "     `I have not the sense of proof,' said Frodo, 'for wh can have been destroyed. The Ringwraiths are destroyed before I desire to keep about all this, and it must go down in the world outside. Gandalf walked in flacks, and welcomed to die, and I understand I call a pony up; but befulted was the chieftap and a cold likely tonsumerth. His farm was hew walking, eastward, but they were searching to the best head and thrust without a struggle. It was difficult to be waiting back to him, and he listened without a string, no less channel that e \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.06624698638916\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model1.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfGIBmgcfhhy",
        "outputId": "3108a0b1-156a-441d-f05e-571c27bdf1fa"
      },
      "id": "qfGIBmgcfhhy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was a sound of wonder and all the others and put in keeping surprisets, for they felt much between Stock and Legolas.\n",
            "     They strode forward from the top pass over the rings above and on either side, and they could not see them away. The valley seemed vanished with a faint step that was now and again; but they were more perilous treasure. And if that was not enough north of Rivendell, and returned to their pale paths broken.\n",
            "     This would turn to start upon the evil of the Downs and flowers, as they breathed. Turning back in the Moon is ran away to the west. In that way they would steaming hostilarcusts and the Lady stopped and waved his cushing from the East. 'Black Riders!' akknow as I caught ' he cried. 'Did I not say. They are only waiting.'\n",
            "     In the morning they went on, too, off the ring had already beaut it and proudly in the darkness.\n",
            "     Frodo laughed green and brows to life.\n",
            "     Twilight filled with a traveller on his ribboush, and leaned against white wolves invade \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.9446358680725098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model2.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNnejohNfieU",
        "outputId": "a50438b6-d099-4a55-9f59-54b99b9cce56"
      },
      "id": "KNnejohNfieU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was a sound of honest lands, or inside. It sought cat still passed to and fro obsiness, Kingdom and Pippin rusked by another thing on for a nice later to Gandalf. Thurs a thing or two others, many times spoken to the floor, and one on either side.\n",
            "     Merry appair sleep leaves, as if strange their bedrooms.\n",
            "     When they caught his words again they found thanks and fell fast asleep at the foot of the stems. It leaned over him. He thought there were twory will get to keep a bit about a _preasunery-giest of wolves, or disturbed me. I never be threw himself from the opposite without there seemed to an incompinion.\n",
            "     `For I must go, between news of the tales, suncernts away for us in this land, now know? \" he said at last, 'I was I think, and I shall not be the master: but I have seldom reached here and all that went with you.\n",
            "           Hey now shone and former low; but that flowed down red behind the mists red Borgir, Ere long, farm, crossing as easily as possible and secret gatero \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.130880355834961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model3.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POEc59rkfioR",
        "outputId": "d414ac2b-1955-435b-fc68-493b15cf72d3"
      },
      "id": "POEc59rkfioR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was something in the look of the fire, they were sea, and below himself with his finger he looked round away, and the shadow of the enemy city of thus to strike the boat outside, and passing through a distand plain below it. A brief ran ahtriling they passed, and they seemed not to travelven swift, and the leaves on some way white girtt fell. But he would not until they found a spring of elven-white, and down news looking scraplich upon the long shadows of stones were laid on much arm us: a strong splun. A suddenly realm in the South, and as the ring is dangerous, far down roots (in came the time was passing through a hollow of the landlord. Pippin and Sam came up with him. It was kept at Great Smials, but it was not by now, and when they had entered the ring had given them for a while feet a little, and they saw the river below him, and they returned to their people. Long ago they found a strick broad sleep, two grey silver, under the night in deep wold, but they came to a narrow pla \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.9362807273864746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model4.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BYvDsL9fiuA",
        "outputId": "4110fe92-c646-482e-985c-13ce0cf4162e"
      },
      "id": "9BYvDsL9fiuA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was a sound of honeshing in the floory, and once they stood, studied it off along the road. There they stood aloot as they bound to the top of a steep bank in a wearing sound, filled with them that shich with water climbed up the stone reluctant that they saw the travellers approached the old in Boromir; and I was there so long ago that the hills have I returned. 'We have any boat before you said, changing still, and many even from the Bree-land and the mountains!' he said suddenly and saw that Land the valley sheet high and looked at him. 'It was this Mr. Frodo and I real your footstench. One by one who  is near the figure to kind it is,' said Legolas.\n",
            "     `A dwarf! ' said Sam. `I thought it was only for a long time to me than that, I can.' Hope Fatty Bolger had joined the know swift to late and holding and a shout of his lips had in rear,\n",
            "           And in the gland singled spell.\n",
            "     'What's that? ' cried Gandalf, spring and went and struggle up a stirl. 'When we go to the woods  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.9254870414733887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['There'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model5.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECPF4Ob0fi0H",
        "outputId": "5a182cb1-5ec7-4e73-e8d7-fc3c84e091d5"
      },
      "id": "ECPF4Ob0fi0H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There was a sound of much the same things and tosssars that could not be found; and in the same combort was made lay.\n",
            "     'And what has the strength, and you cannot enough, Mr. Underhill?' he asked. 'It wouldn't keep a horrible new, but to give you away; but I guess that in that cries would not be dark before now. As the road that I seek for him, even when he is strong or badgest two barges and deads to presive needs that I cannot linger than travellers. Grove from the Shire! '\n",
            "     'Ride all things and places now the passage from the Seven and the Old, `not at any rate here. I may have started your touched without rest. And one thing were to do without relating about his father's tired. Enormous in the northward trees. They won't get it. I won't give my precious away, I tell you,' said Celeborn. `So you go on by rider by the news after those two youn holes, and I could not \"know,' answered Gandalf, 'but before that he had wandered far, free to answer at once. And yet well enough do not no \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.941152572631836\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Project 4.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}