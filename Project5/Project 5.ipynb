{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef2c4fc",
   "metadata": {},
   "source": [
    "# Spring 2022\n",
    "# CPSC 585 Project 5\n",
    "## Raymond Carpio\n",
    "## Yu Pan\n",
    "## Sijie Shang\n",
    "## John Tu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90284f",
   "metadata": {},
   "source": [
    "# 1. Begin with the Keras example Collaborative Filtering for Movie Recommendations and verify that you can obtain the sample examples.\n",
    "## This example uses the Keras Embedding layer type. While it may not be clear from the documentation, this layer type can be used to build an autoencoder. For example, to build the basic autoencoder of Figure 2.7 on p. 73 of the textbook, you could stack together an Embedding layer with input_dim 5 and output_dim 3 with another Embedding layer with input_dim 3 and output_dim 5.\n",
    "## While this could obviously be done instead using a single Dense hidden layer, the difference is that Embedding layers work well with sparse data (e.g. where users have not rated most movies in the dataset.)\n",
    "## As a result, the model corresponds roughly to the matrix factorization shown in Figure 2.13 on p. 84 of the textbook, using the dot product to compute the similarity of the user and movie vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d416af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb2fbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Use the ratings.csv file\n",
    "movielens_data_file_url = (\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    ")\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    \"ml-latest-small.zip\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-latest-small\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "ratings_file = movielens_dir / \"ratings.csv\"\n",
    "df = pd.read_csv(ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552f8c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e14fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# Assuming training on 90% of the data and validating on 10%.\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9350c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return tf.nn.sigmoid(x)\n",
    "\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f24f31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1418/1418 [==============================] - 10s 7ms/step - loss: 0.6366 - val_loss: 0.6214\n",
      "Epoch 2/5\n",
      "1418/1418 [==============================] - 9s 6ms/step - loss: 0.6133 - val_loss: 0.6181\n",
      "Epoch 3/5\n",
      "1418/1418 [==============================] - 9s 6ms/step - loss: 0.6083 - val_loss: 0.6143\n",
      "Epoch 4/5\n",
      "1418/1418 [==============================] - 9s 6ms/step - loss: 0.6068 - val_loss: 0.6145\n",
      "Epoch 5/5\n",
      "1418/1418 [==============================] - 10s 7ms/step - loss: 0.6064 - val_loss: 0.6132\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e30e62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e466239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 356\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Casablanca (1942) : Drama|Romance\n",
      "Empire Records (1995) : Comedy|Drama\n",
      "Sandlot, The (1993) : Children|Comedy|Drama\n",
      "Hours, The (2002) : Drama|Romance\n",
      "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Rear Window (1954) : Mystery|Thriller\n",
      "Goodfellas (1990) : Crime|Drama\n",
      "Cool Hand Luke (1967) : Drama\n",
      "Omen, The (1976) : Horror|Mystery|Thriller\n",
      "Star Trek: First Contact (1996) : Action|Adventure|Sci-Fi|Thriller\n",
      "Shine (1996) : Drama|Romance\n",
      "American History X (1998) : Crime|Drama\n",
      "Boondock Saints, The (2000) : Action|Crime|Drama|Thriller\n",
      "Outlaw Josey Wales, The (1976) : Action|Adventure|Drama|Thriller|Western\n",
      "Strada, La (1954) : Drama\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv(movielens_dir / \"movies.csv\")\n",
    "\n",
    "# Let us get a user and see the top recommendations.\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "#print(movies_watched_by_user)\n",
    "\n",
    "def recommender_1(movies_watched_by_user):\n",
    "    movies_not_watched = movie_df[\n",
    "        ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "    ][\"movieId\"]\n",
    "    movies_not_watched = list(\n",
    "        set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    "    )\n",
    "    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "\n",
    "    user_encoder = user2user_encoded.get(user_id)\n",
    "    user_movie_array = np.hstack(\n",
    "        ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    "    )\n",
    "    ratings = model.predict(user_movie_array).flatten()\n",
    "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "    recommended_movie_ids = [\n",
    "        movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "    ]\n",
    "\n",
    "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "    print(\"====\" * 9)\n",
    "    print(\"Movies with high ratings from user\")\n",
    "    print(\"----\" * 8)\n",
    "    top_movies_user = (\n",
    "        movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "        .head(5)\n",
    "        .movieId.values\n",
    "    )\n",
    "    movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "    for row in movie_df_rows.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "\n",
    "    print(\"----\" * 8)\n",
    "    print(\"Top 10 movie recommendations\")\n",
    "    print(\"----\" * 8)\n",
    "    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "    for row in recommended_movies.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "recommender_1(movies_watched_by_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a139cd98",
   "metadata": {},
   "source": [
    "# 2. Construct a feature vector for one or move members of your team, choosing and rating several movies that they have seen. (Do not rate all movies that they have seen — leave room for recommendations.)\n",
    "# What other movies does the network recommend? How many of the recommended movies have they actually seen? Were the recommendations accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ad29c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 356\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Toy Story (1995) : Adventure|Animation|Children|Comedy|Fantasy\n",
      "Toy Story 2 (1999) : Adventure|Animation|Children|Comedy|Fantasy\n",
      "Harry Potter and the Prisoner of Azkaban (2004) : Adventure|Fantasy|IMAX\n",
      "Pride & Prejudice (2005) : Drama|Romance\n",
      "Avengers: Infinity War - Part I (2018) : Action|Adventure|Sci-Fi\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Forrest Gump (1994) : Comedy|Drama|Romance|War\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) : Comedy|War\n",
      "Matrix, The (1999) : Action|Sci-Fi|Thriller\n",
      "Fight Club (1999) : Action|Crime|Drama|Thriller\n",
      "Boondock Saints, The (2000) : Action|Crime|Drama|Thriller\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001) : Adventure|Fantasy\n",
      "Lord of the Rings: The Return of the King, The (2003) : Action|Adventure|Drama|Fantasy\n",
      "There Will Be Blood (2007) : Drama|Western\n",
      "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n"
     ]
    }
   ],
   "source": [
    "rated_movies = {'userId': [999,999,999,999,999,999,999,999,999,999], 'movieId': [1,3114,8368,40815,40629,176101,135536,129779,122924,122912], 'rating': [4,4,4,4,5,4,3,3.5,4,5]}\n",
    "movies_watched_by_user = pd.DataFrame(rated_movies)\n",
    "recommender_1(movies_watched_by_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29cdc8",
   "metadata": {},
   "source": [
    "## A: The movies that the system recommends based on watch history are listed above in the Top 10 movie recommendations list. Based on the genres listed from the recommendations list, the only genres that are relevant based on user's watch history are Comedy, Action, and Adventure. Thus, the recommendations are not somewhat accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90263320",
   "metadata": {},
   "source": [
    "# 3. While the matrix factorization model described in the textbook relies on only a single dense hidden layer (or equivalently, two hidden embedding layers), it should be possible to achieve better results with a deeper network.\n",
    "# Replace the dot product with one or more dense layers, allowing the network to learn relationships between the user and movie vectors. Compare the performance of the network on the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b06b83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer (Dense)         (None, 200)               600       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " OutputLayer (Dense)         (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801\n",
      "Trainable params: 801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instead of modifying the existing model from Problem 1, build a new model with a Dense hidden layer.\n",
    "model2 = tf.keras.Sequential()\n",
    "model2.add(tf.keras.Input(shape=(2,)))\n",
    "model2.add(tf.keras.layers.Dense(200, activation=\"relu\", name=\"HiddenLayer\"))\n",
    "model2.add(tf.keras.layers.Flatten())\n",
    "model2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"OutputLayer\"))\n",
    "\n",
    "model2.summary()\n",
    "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c4a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1418/1418 [==============================] - 2s 929us/step - loss: 1.4455 - val_loss: 1.7093\n",
      "Epoch 2/5\n",
      "1418/1418 [==============================] - 1s 1ms/step - loss: 1.1905 - val_loss: 1.0352\n",
      "Epoch 3/5\n",
      "1418/1418 [==============================] - 2s 2ms/step - loss: 1.2394 - val_loss: 0.7234\n",
      "Epoch 4/5\n",
      "1418/1418 [==============================] - 2s 1ms/step - loss: 1.1899 - val_loss: 0.6444\n",
      "Epoch 5/5\n",
      "1418/1418 [==============================] - 2s 1ms/step - loss: 1.1021 - val_loss: 1.1108\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2e7ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 318\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Marat/Sade (1966) : Drama|Musical\n",
      "Woman Under the Influence, A (1974) : Drama\n",
      "Fast Food Nation (2006) : Drama\n",
      "Django Unchained (2012) : Action|Drama|Western\n",
      "Interstellar (2014) : Sci-Fi|IMAX\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Very Bad Things (1998) : Comedy|Crime\n",
      "Psycho (1998) : Crime|Horror|Thriller\n",
      "Romancing the Stone (1984) : Action|Adventure|Comedy|Romance\n",
      "Young Sherlock Holmes (1985) : Action|Adventure|Children|Fantasy|Mystery|Thriller\n",
      "Howard the Duck (1986) : Adventure|Comedy|Sci-Fi\n",
      "Texas Chainsaw Massacre, The (1974) : Horror\n",
      "Crocodile Dundee (1986) : Adventure|Comedy\n",
      "¡Three Amigos! (1986) : Comedy|Western\n",
      "20 Dates (1998) : Comedy|Romance\n",
      "SLC Punk! (1998) : Comedy|Drama\n"
     ]
    }
   ],
   "source": [
    "# Follow the same procedure from Problem 1, except try a different user id.\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "#print(movies_watched_by_user)\n",
    "\n",
    "def recommender_2(movies_watched_by_user):\n",
    "    movies_not_watched = movie_df[\n",
    "        ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "    ][\"movieId\"]\n",
    "    movies_not_watched = list(\n",
    "        set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    "    )\n",
    "    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "\n",
    "    user_encoder = user2user_encoded.get(user_id)\n",
    "    user_movie_array = np.hstack(\n",
    "        ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    "    )\n",
    "    ratings = model2.predict(user_movie_array).flatten()\n",
    "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "    recommended_movie_ids = [\n",
    "        movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "    ]\n",
    "\n",
    "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "    print(\"====\" * 9)\n",
    "    print(\"Movies with high ratings from user\")\n",
    "    print(\"----\" * 8)\n",
    "    top_movies_user = (\n",
    "        movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "        .head(5)\n",
    "        .movieId.values\n",
    "    )\n",
    "    movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "    for row in movie_df_rows.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "\n",
    "    print(\"----\" * 8)\n",
    "    print(\"Top 10 movie recommendations\")\n",
    "    print(\"----\" * 8)\n",
    "    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "    for row in recommended_movies.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "recommender_2(movies_watched_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049c85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing recommendations for user: 318\n",
      "====================================\n",
      "Movies with high ratings from user\n",
      "--------------------------------\n",
      "Toy Story (1995) : Adventure|Animation|Children|Comedy|Fantasy\n",
      "Toy Story 2 (1999) : Adventure|Animation|Children|Comedy|Fantasy\n",
      "Harry Potter and the Prisoner of Azkaban (2004) : Adventure|Fantasy|IMAX\n",
      "Pride & Prejudice (2005) : Drama|Romance\n",
      "Avengers: Infinity War - Part I (2018) : Action|Adventure|Sci-Fi\n",
      "--------------------------------\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Thin Red Line, The (1998) : Action|Drama|War\n",
      "Howard the Duck (1986) : Adventure|Comedy|Sci-Fi\n",
      "Texas Chainsaw Massacre, The (1974) : Horror\n",
      "Crocodile Dundee (1986) : Adventure|Comedy\n",
      "¡Three Amigos! (1986) : Comedy|Western\n",
      "20 Dates (1998) : Comedy|Romance\n",
      "Office Space (1999) : Comedy|Crime\n",
      "Logan's Run (1976) : Action|Adventure|Sci-Fi\n",
      "Planet of the Apes (1968) : Action|Drama|Sci-Fi\n",
      "Lock, Stock & Two Smoking Barrels (1998) : Comedy|Crime|Thriller\n"
     ]
    }
   ],
   "source": [
    "# This snippet of code is imported from problem 2, and will be used to compare results for problem 3.\n",
    "rated_movies = {'userId': [999,999,999,999,999,999,999,999,999,999], 'movieId': [1,3114,8368,40815,40629,176101,135536,129779,122924,122912], 'rating': [4,4,4,4,5,4,3,3.5,4,5]}\n",
    "movies_watched_by_user = pd.DataFrame(rated_movies)\n",
    "recommender_2(movies_watched_by_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b289e",
   "metadata": {},
   "source": [
    "# 4. Compare the quality of the recommendations from experiment (2) with those of the new network of experiment (3). Does the recommendation performance improve for the members of your team?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320162f",
   "metadata": {},
   "source": [
    "## A: The recommendations from experiment 2 shows Drama movies as the top 10 recommedations, and for the user, 8 movies watched by the user is Drama. For experiment 3, two recommendation models are created by using the Dense layer network, and there are some issues regarding about the performance. For the first one, the movies that the user watched are Action movies, while the second one contains watched movies with Adventure and Fantasy genres as the most common. The top 10 recommendations for both models contain Thriller as the most recurring genre, in which although this can be said true for the 3 movies that the user has watched, none of those can be applied to the movies that the user has watched for the second model. Thus, the recommendation performance has not yet improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f92c7b",
   "metadata": {},
   "source": [
    "# 5. If you were disappointed by the results of experiments (3) and (4), your network may be suffering from the problem shown in Figure 2.11 on p. 79 of the textbook, where the hidden layers do a poor job mapping out-of-sample data points to reduced representations. This is exactly the problem addressed by variational autoencoders.\n",
    "# Use the Keras example Variational AutoEncoder to add an additional sampling layer to your network.\n",
    "## Note: although much of the code is specific to building a convolutional VAE, you will also need to customize the training process as shown in the example in order to implement the loss function of Equations 4.17 through 4.19 on p. 208 of the textbook.\n",
    "# Compare the performance of this network with those in experiments (1) and (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01efbb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf29cd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 50, 610, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " HiddenLayer (Dense)            (None, 50, 610, 200  400         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 6100000)      0           ['HiddenLayer[0][0]']            \n",
      "                                                                                                  \n",
      " OutputLayer (Dense)            (None, 1)            6100001     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            4           ['OutputLayer[0][0]']            \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            4           ['OutputLayer[0][0]']            \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,100,409\n",
      "Trainable params: 6,100,409\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "# Instead of modifying the existing model from Problem 1, build a new model with a Dense hidden layer.\n",
    "encoder_inputs = keras.Input(shape=(50, 610, 1))\n",
    "#encoder.add(tf.keras.Input(shape=(2,)))\n",
    "x = tf.keras.layers.Dense(200, activation=\"relu\", name=\"HiddenLayer\")(encoder_inputs)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"OutputLayer\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "#encoder.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d700f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6100000)           18300000  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 50, 610, 200)      0         \n",
      "                                                                 \n",
      " OutputLayer (Dense)         (None, 50, 610, 200)      40200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,340,200\n",
      "Trainable params: 18,340,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(50 *610 *200, activation=\"sigmoid\")(latent_inputs)\n",
    "x = layers.Reshape((50, 610, 200))(x)\n",
    "decoder_outputs = tf.keras.layers.Dense(200, activation=\"relu\", name=\"OutputLayer\")(x)\n",
    "#decoder_outputs = layers.Dense(1, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b46533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888ebd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90752, 2)\n",
      "(90752,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6eddb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\johnt\\AppData\\Local\\Temp/ipykernel_9396/3236315084.py\", line 22, in train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"encoder\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(128, 2) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(128,) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m vae \u001b[38;5;241m=\u001b[39m VAE(encoder, decoder)\n\u001b[0;32m      2\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam())\n\u001b[1;32m----> 3\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\johnt\\AppData\\Local\\Temp/ipykernel_9396/3236315084.py\", line 22, in train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"encoder\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(128, 2) dtype=int64>, <tf.Tensor 'IteratorGetNext:1' shape=(128,) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(x=x_train, y=y_train, epochs=30, batch_size=128,validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cf1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "#print(movies_watched_by_user)\n",
    "\n",
    "def recommender_3(movies_watched_by_user):\n",
    "    movies_not_watched = movie_df[\n",
    "        ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "    ][\"movieId\"]\n",
    "    movies_not_watched = list(\n",
    "        set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    "    )\n",
    "    movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "\n",
    "    user_encoder = user2user_encoded.get(user_id)\n",
    "    user_movie_array = np.hstack(\n",
    "        ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    "    )\n",
    "    ratings = vae.predict(user_movie_array).flatten()\n",
    "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "    recommended_movie_ids = [\n",
    "        movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "    ]\n",
    "\n",
    "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
    "    print(\"====\" * 9)\n",
    "    print(\"Movies with high ratings from user\")\n",
    "    print(\"----\" * 8)\n",
    "    top_movies_user = (\n",
    "        movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "        .head(5)\n",
    "        .movieId.values\n",
    "    )\n",
    "    movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "    for row in movie_df_rows.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "\n",
    "    print(\"----\" * 8)\n",
    "    print(\"Top 10 movie recommendations\")\n",
    "    print(\"----\" * 8)\n",
    "    recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "    for row in recommended_movies.itertuples():\n",
    "        print(row.title, \":\", row.genres)\n",
    "recommender_3(movies_watched_by_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_movies = {'userId': [999,999,999,999,999,999,999,999,999,999], 'movieId': [1,3114,8368,40815,40629,176101,135536,129779,122924,122912], 'rating': [4,4,4,4,5,4,3,3.5,4,5]}\n",
    "movies_watched_by_user = pd.DataFrame(rated_movies)\n",
    "recommender_3(movies_watched_by_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
